
@misc{115BuTongDeZiXuLieLiKou,
  title = {115. 不同的子序列 - 力扣（{{LeetCode}}）},
  abstract = {给定一个字符串 s 和一个字符串 t ，计算在 s 的子序列中 t 出现的个数。 字符串的一个 子序列 是指，通过删除一些（也可以不删除）字符且不干扰剩余字符相对位置所组成的新字符串。（例如，"ACE" 是 "ABCDE" 的一个子序列，而 "AEC" 不是） 题目数据保证答案符合 32 位带符号整数范围。 示例 1： 输入：s = "rabbbit", t = "rabbit" 输出：3 解释： 如下图所示, 有 3 种可以从 s 中得到 "rabbit" 的方案。 (上箭头符号 \^ 表示选取的字母) rabbbit \^\^\^\^ \^\^ rabbbit \^\^ \^\^\^\^ rabbbit \^\^\^ \^\^\^ 示例 2： 输入：s = "babgbag", t = "bag" 输出：5 解释： 如下图所示, 有 5 种可以从 s 中得到 "bag" 的方案。 (上箭头符号 \^ 表示选取的字母) babgbag \^\^ \^ babgbag \^\^ \^ babgbag \^ \^\^ babgbag \^ \^\^ babgbag \^\^\^ 提示： 0 {$<$}= s.length, t.length {$<$}= 1000 s 和 t 由英文字母组成。115. Distinct Subsequences: Given two strings s and t, return the number of distinct subsequences of s which equals t. A string's subsequence is a new string formed from the original string by deleting some (can be none) of the characters without disturbing the remaining characters' relative positions. (i.e., "ACE" is a subsequence of "ABCDE" while "AEC" is not). It is guaranteed the answer fits on a 32-bit signed integer. Example 1: Input: s = "rabbbit", t = "rabbit" Output: 3 Explanation: As shown below, there are 3 ways you can generate "rabbit" from S. rabbbit rabbbit rabbbit Example 2: Input: s = "babgbag", t = "bag" Output: 5 Explanation: As shown below, there are 5 ways you can generate "bag" from S. babgbag babgbag babgbag babgbag babgbag Constraints: 0 {$<$}= s.length, t.length {$<$}= 1000 s and t consist of English letters.},
  file = {E\:\\Zotero\\storage\\DPVZ86MB\\distinct-subsequences.html},
  howpublished = {https://leetcode-cn.com/problems/distinct-subsequences/},
  journal = {力扣 LeetCode}
}

@inproceedings{abadiTensorFlowSystemLargeScale2016,
  title = {{{TensorFlow}}: {{A System}} for {{Large}}-{{Scale Machine Learning}}},
  shorttitle = {{{TensorFlow}}},
  booktitle = {12th \{\vphantom\}{{USENIX}}\vphantom\{\} {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\{\vphantom\}{{OSDI}}\vphantom\{\} 16)},
  author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2016},
  pages = {265--283},
  file = {E\:\\Zotero\\storage\\HCQFZXV5\\Abadi et al_2016_TensorFlow.pdf;E\:\\Zotero\\storage\\3SFH8XFL\\abadi.html},
  isbn = {978-1-931971-33-1},
  keywords = {_to_read},
  language = {en}
}

@inproceedings{agarwalDistributedDelayedStochastic2012,
  title = {Distributed Delayed Stochastic Optimization},
  booktitle = {2012 {{IEEE}} 51st {{IEEE Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Agarwal, Alekh and Duchi, John C.},
  year = {2012},
  pages = {5451--5452},
  publisher = {{IEEE}},
  doi = {10/ghv43q},
  file = {E\:\\Zotero\\storage\\NGBA4BJB\\6426626.html}
}

@inproceedings{alipourfardCherryPickAdaptivelyUnearthing2017,
  title = {{{CherryPick}}: {{Adaptively Unearthing}} the {{Best Cloud Configurations}} for {{Big Data Analytics}}},
  shorttitle = {{{CherryPick}}},
  booktitle = {14th \{\vphantom\}{{USENIX}}\vphantom\{\} {{Symposium}} on {{Networked Systems Design}} and {{Implementation}} (\{\vphantom\}{{NSDI}}\vphantom\{\} 17)},
  author = {Alipourfard, Omid and Liu, Hongqiang Harry and Chen, Jianshu and Venkataraman, Shivaram and Yu, Minlan and Zhang, Ming},
  year = {2017},
  pages = {469--482},
  file = {E\:\\Zotero\\storage\\JVZG2ZDW\\Alipourfard et al_2017_CherryPick.pdf;E\:\\Zotero\\storage\\XD292HTX\\Errata_Alipourfard et al_2017_CherryPick.pdf;E\:\\Zotero\\storage\\XQGMCA2R\\alipourfard.html},
  isbn = {978-1-931971-37-9},
  language = {en}
}

@inproceedings{andersonAssisePerformanceAvailability2020,
  title = {Assise: {{Performance}} and {{Availability}} via {{Client}}-Local \$\{\$\vphantom\}{{NVM}}\$\vphantom\{\}\$ in a {{Distributed File System}}},
  shorttitle = {Assise},
  booktitle = {14th \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\$\{\$\vphantom\}{{OSDI}}\$\vphantom\{\}\$ 20)},
  author = {Anderson, Thomas E. and Canini, Marco and Kim, Jongyul and Kosti{\'c}, Dejan and Kwon, Youngjin and Peter, Simon and Reda, Waleed and Schuh, Henry N. and Witchel, Emmett},
  year = {2020},
  pages = {1011--1027},
  file = {E\:\\Zotero\\storage\\I47JXT35\\Anderson et al_2020_Assise.pdf;E\:\\Zotero\\storage\\TRCK9Q8D\\anderson.html}
}

@book{ashProbabilityMeasureTheory2000,
  title = {Probability and Measure Theory},
  author = {Ash, Robert B. and {Dol{\'e}ans-Dade}, Catherine and Ash, Robert B.},
  year = {2000},
  edition = {2nd ed},
  publisher = {{Harcourt/Academic Press}},
  address = {{San Diego}},
  file = {E\:\\Zotero\\storage\\XNKWAZLZ\\Ash et al_2000_Probability and measure theory.pdf},
  isbn = {978-0-12-065202-0},
  keywords = {Mathematical analysis,Probabilities},
  lccn = {QA273 .A775 2000}
}

@book{bengioLearningSynapticLearning1990,
  title = {Learning a Synaptic Learning Rule},
  author = {Bengio, Yoshua and Bengio, Samy and Cloutier, Jocelyn},
  year = {1990},
  publisher = {{Citeseer}},
  file = {E\:\\Zotero\\storage\\XFIH4J2E\\Bengio et al_1990_Learning a synaptic learning rule.pdf},
  keywords = {math-thesis}
}

@book{bertsekasConvexOptimizationTheory2009,
  title = {Convex Optimization Theory},
  author = {Bertsekas, Dimitri P.},
  year = {2009},
  publisher = {{Athena Scientific}},
  address = {{Belmont, Massachusetts}},
  abstract = {Literaturverzeichnis: Seiten 240 - 242},
  annotation = {OCLC: 746128360},
  file = {E\:\\Zotero\\storage\\62AL82XS\\Supplement_Bertsekas_2009_Convex optimization theory.pdf;E\:\\Zotero\\storage\\L39RPMKB\\Bertsekas - 2009 - Convex optimization theory.pdf},
  isbn = {978-1-886529-31-1},
  language = {en},
  number = {1},
  series = {Optimization and Computation Series}
}

@book{bertsekasReinforcementLearningOptimal2019,
  title = {Reinforcement Learning and Optimal Control},
  author = {Bertsekas, Dimitri P},
  year = {2019},
  abstract = {"This book explores the common boundary between optimal control and artificial intelligence, as it relates to reinforcement learning and simulation-based neural network methods. These are popular fields with many applications, which can provide approximate solutions to challenging sequential decision problems and large-scale dynamic programming (DP). The aim of the book is to organize coherently the broad mosaic of methods in these fields, which have a solid analytical and logical foundation, and have also proved successful in practice"--OhioLink Library Catalog.},
  annotation = {OCLC: 1151095080},
  file = {E\:\\Zotero\\storage\\5NUUG7JK\\Bertsekas_2019_Reinforcement learning and optimal control.pdf;E\:\\Zotero\\storage\\B5MIQSD5\\RL_CH1_ROLLOUT_CLASS_NOTES.pdf},
  isbn = {978-1-886529-39-7},
  keywords = {math-thesis,math-thesis:book},
  language = {English}
}

@inproceedings{bingmannThrillHighperformanceAlgorithmic2016,
  title = {Thrill: {{High}}-Performance Algorithmic Distributed Batch Data Processing with {{C}}++},
  shorttitle = {Thrill},
  booktitle = {2016 {{IEEE International Conference}} on {{Big Data}} ({{Big Data}})},
  author = {Bingmann, Timo and Axtmann, Michael and Jobstl, Emanuel and Lamm, Sebastian and Nguyen, Huyen Chau and Noe, Alexander and Schlag, Sebastian and Stumpp, Matthias and Sturm, Tobias and Sanders, Peter},
  year = {2016},
  month = dec,
  pages = {172--183},
  publisher = {{IEEE}},
  address = {{Washington DC,USA}},
  doi = {10/gfspqw},
  abstract = {We present the design and a first performance evaluation of Thrill \textendash{} a prototype of a general purpose big data processing framework with a convenient data-flow style programming interface. Thrill is somewhat similar to Apache Spark and Apache Flink with at least two main differences. First, Thrill is based on C++ which enables performance advantages due to direct native code compilation, a more cachefriendly memory layout, and explicit memory management. In particular, Thrill uses template meta-programming to compile chains of subsequent local operations into a single binary routine without intermediate buffering and with minimal indirections. Second, Thrill uses arrays rather than multisets as its primary data structure which enables additional operations like sorting, prefix sums, window scans, or combining corresponding fields of several arrays (zipping).},
  file = {E\:\\Zotero\\storage\\PI2867SZ\\Bingmann et al_2016_Thrill.pdf},
  isbn = {978-1-4673-9005-7},
  language = {en}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  publisher = {{Springer}},
  address = {{New York}},
  file = {E\:\\Zotero\\storage\\7HEGP58D\\Bishop - 2006 - Pattern recognition and machine learning.pdf;E\:\\Zotero\\storage\\8NG3TKSS\\Answer_Bishop_2006_Pattern recognition and machine learning.pdf;E\:\\Zotero\\storage\\GXDNMAF3\\Chinese_Bishop_2006_Pattern recognition and machine learning.pdf;E\:\\Zotero\\storage\\TSZQQR92\\Errata_Pattern Recognition and Machine Learning Errata and Additional Comments.pdf},
  isbn = {978-0-387-31073-2},
  keywords = {_reading,_to_read,Machine learning,Pattern perception},
  language = {en},
  lccn = {Q327 .B52 2006},
  series = {Information Science and Statistics}
}

@book{bonannoGameTheory2018,
  title = {Game Theory 1, 1,},
  author = {Bonanno, Giacomo},
  year = {2018},
  annotation = {OCLC: 1224016545},
  file = {E\:\\Zotero\\storage\\SK2TRB53\\Bonanno - 2018 - Game theory 1, 1,.pdf},
  isbn = {978-1-983604-63-8},
  language = {en}
}

@book{boydConvexOptimization2004,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  year = {2004},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK ; New York}},
  file = {E\:\\Zotero\\storage\\2DBFVNU9\\Boyd_Vandenberghe_2004_Convex optimization_slides.pdf;E\:\\Zotero\\storage\\D2PCCL3N\\Boyd_Vandenberghe_2004_Convex optimization.pdf},
  isbn = {978-0-521-83378-3},
  keywords = {Convex functions,Mathematical optimization},
  language = {en},
  lccn = {QA402.5 .B69 2004}
}

@book{boydTuYouHuaConvexOptimization2013,
  title = {{凸优化 = Convex optimization}},
  author = {Boyd, Stephen and Vandenberghe, Lieven and {王书宁} and {许鋆} and {黄晓霖}},
  year = {2013},
  publisher = {{清华大学出版社}},
  address = {{北京}},
  annotation = {OCLC: 840387603},
  file = {E\:\\Zotero\\storage\\KH8U8BFP\\Boyd et al_2013_凸优化 = Convex optimization.pdf},
  isbn = {978-7-302-29756-7},
  language = {Chinese}
}

@book{chenxiruGaoDengShuLiTongJiXue2009,
  title = {{高等数理统计学}},
  author = {{陈希孺}},
  year = {2009},
  publisher = {{中国科学技术大学出版社}},
  address = {{合肥}},
  annotation = {OCLC: 956428117},
  file = {E\:\\Zotero\\storage\\A9WW8NNR\\陈希孺_2009_高等数理统计学.pdf;E\:\\Zotero\\storage\\SYEAJLRY\\样章 高等数理统计学.pdf},
  isbn = {978-7-312-02281-4},
  language = {Chinese}
}

@book{chenxiruShuLiTongJiYinLun2007,
  title = {{数理统计引论}},
  author = {{陈希孺}},
  year = {2007},
  publisher = {{科学出版社}},
  address = {{北京}},
  annotation = {OCLC: 1128224994},
  file = {E\:\\Zotero\\storage\\HKZUHAP6\\陈希孺_2007_数理统计引论.pdf},
  isbn = {978-7-03-006047-1},
  language = {Chinese}
}

@article{coteTextWorldLearningEnvironment2019,
  title = {{{TextWorld}}: {{A Learning Environment}} for {{Text}}-Based {{Games}}},
  shorttitle = {{{TextWorld}}},
  author = {C{\^o}t{\'e}, Marc-Alexandre and K{\'a}d{\'a}r, {\'A}kos and Yuan, Xingdi and Kybartas, Ben and Barnes, Tavian and Fine, Emery and Moore, James and Tao, Ruo Yu and Hausknecht, Matthew and Asri, Layla El and Adada, Mahmoud and Tay, Wendy and Trischler, Adam},
  year = {2019},
  month = nov,
  abstract = {We introduce TextWorld, a sandbox learning environment for the training and evaluation of RL agents on text-based games. TextWorld is a Python library that handles interactive play-through of text games, as well as backend functions like state tracking and reward assignment. It comes with a curated list of games whose features and challenges we have analyzed. More significantly, it enables users to handcraft or automatically generate new games. Its generative mechanisms give precise control over the difficulty, scope, and language of constructed games, and can be used to relax challenges inherent to commercial text games like partial observability and sparse rewards. By generating sets of varied but similar games, TextWorld can also be used to study generalization and transfer learning. We cast text-based games in the Reinforcement Learning formalism, use our framework to develop a set of benchmark games, and evaluate several baseline agents on this set and the curated list.},
  archiveprefix = {arXiv},
  eprint = {1806.11532},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\KTGNHIEH\\Côté et al_2019_TextWorld.pdf;E\:\\Zotero\\storage\\3YICMCWQ\\1806.html},
  journal = {arXiv:1806.11532 [cs, stat]},
  keywords = {⛔ No DOI found,Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@inproceedings{danelljanATOMAccurateTracking2019,
  title = {{{ATOM}}: {{Accurate Tracking}} by {{Overlap Maximization}}},
  shorttitle = {{{ATOM}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Danelljan, Martin and Bhat, Goutam and Khan, Fahad Shahbaz and Felsberg, Michael},
  year = {2019},
  month = jun,
  pages = {4655--4664},
  publisher = {{IEEE}},
  address = {{Long Beach, CA, USA}},
  doi = {10/ghrmz7},
  abstract = {While recent years have witnessed astonishing improvements in visual tracking robustness, the advancements in tracking accuracy have been limited. As the focus has been directed towards the development of powerful classifiers, the problem of accurate target state estimation has been largely overlooked. In fact, most trackers resort to a simple multi-scale search in order to estimate the target bounding box. We argue that this approach is fundamentally limited since target estimation is a complex task, requiring highlevel knowledge about the object.},
  file = {E\:\\Zotero\\storage\\LL4TKJ6S\\Danelljan et al. - 2019 - ATOM Accurate Tracking by Overlap Maximization.pdf},
  isbn = {978-1-72813-293-8},
  keywords = {_no_read,CVPR},
  language = {en}
}

@book{dasGeneralTheoryRelativity2012,
  title = {The {{General Theory}} of {{Relativity}}},
  author = {Das, Anadijiban and DeBenedictis, Andrew},
  year = {2012},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-3658-4},
  file = {E\:\\Zotero\\storage\\VZLWYZEF\\Das_DeBenedictis_2012_The General Theory of Relativity.pdf},
  isbn = {978-1-4614-3657-7 978-1-4614-3658-4},
  language = {en}
}

@article{dempsterMaximumLikelihoodIncomplete1977,
  title = {Maximum {{Likelihood}} from {{Incomplete Data Via}} the {{EM Algorithm}}},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  year = {1977},
  volume = {39},
  pages = {1--22},
  issn = {2517-6161},
  doi = {10/gfxzrv},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1977.tb01600.x},
  file = {E\:\\Zotero\\storage\\HYBT6NTF\\Dempster et al_1977_Maximum Likelihood from Incomplete Data Via the EM Algorithm.pdf;E\:\\Zotero\\storage\\6S65433B\\j.2517-6161.1977.tb01600.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  keywords = {em algorithm,incomplete data,maximum likelihood,posterior mode},
  language = {en},
  number = {1}
}

@book{dengdonggaoShiBianHanShuJianMingJiaoCheng2005,
  title = {{实变函数简明教程}},
  author = {{邓东皋} and {常心怡}},
  year = {2005},
  publisher = {{高等教育出版社}},
  address = {{北京}},
  annotation = {OCLC: 1159380566},
  file = {E\:\\Zotero\\storage\\7BA35RU2\\邓东皋_常心怡_2005_实变函数简明教程.pdf},
  isbn = {978-7-04-016700-9},
  language = {Chinese}
}

@book{dengdonggaoShuXueFenXiJianMingJiaoChengShangCeShangCe2006,
  title = {{数学分析简明教程. 上册 上册}},
  author = {{邓东皋} and {尹小玲}},
  year = {2006},
  publisher = {{高等教育出版社}},
  address = {{北京}},
  annotation = {OCLC: 1159590067},
  file = {E\:\\Zotero\\storage\\9K3DR43J\\邓东皋_尹小玲_2006_数学分析简明教程.pdf},
  isbn = {978-7-04-018662-8},
  language = {Chinese}
}

@book{dengdonggaoShuXueFenXiJianMingJiaoChengXiaCeXiaCe2006,
  title = {{数学分析简明教程. 下册 下册}},
  author = {{邓东皋} and {尹小玲}},
  year = {2006},
  publisher = {{高等教育出版社}},
  address = {{北京}},
  annotation = {OCLC: 1159518422},
  file = {E\:\\Zotero\\storage\\NEQUY5JA\\邓东皋_尹小玲_2006_数学分析简明教程.pdf},
  isbn = {978-7-04-019954-3},
  language = {Chinese}
}

@article{devlinBERTPretrainingDeep2019,
  ids = {devlinBERTPretrainingDeep2019a},
  title = {{{BERT}}: {{Pre}}-Training of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  eprint = {1810.04805},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\NX529QLV\\Devlin et al_2019_BERT.pdf;E\:\\Zotero\\storage\\Y7CCY56K\\1810.html},
  journal = {arXiv:1810.04805 [cs]},
  keywords = {⛔ No DOI found,Computer Science - Computation and Language},
  primaryclass = {cs}
}

@article{devriesLearningConfidenceOutofDistribution2018,
  title = {Learning {{Confidence}} for {{Out}}-of-{{Distribution Detection}} in {{Neural Networks}}},
  author = {DeVries, Terrance and Taylor, Graham W.},
  year = {2018},
  month = feb,
  abstract = {Modern neural networks are very powerful predictive models, but they are often incapable of recognizing when their predictions may be wrong. Closely related to this is the task of out-of-distribution detection, where a network must determine whether or not an input is outside of the set on which it is expected to safely perform. To jointly address these issues, we propose a method of learning confidence estimates for neural networks that is simple to implement and produces intuitively interpretable outputs. We demonstrate that on the task of out-of-distribution detection, our technique surpasses recently proposed techniques which construct confidence based on the network's output distribution, without requiring any additional labels or access to out-of-distribution examples. Additionally, we address the problem of calibrating out-of-distribution detectors, where we demonstrate that misclassified in-distribution examples can be used as a proxy for out-of-distribution examples.},
  archiveprefix = {arXiv},
  eprint = {1802.04865},
  eprinttype = {arxiv},
  journal = {arXiv:1802.04865 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{dimitrip.bertsekasREINFORCEMENTLEARNINGOPTIMAL,
  title = {{{REINFORCEMENT LEARNING AND OPTIMAL CONTROL}}},
  author = {{Dimitri P. Bertsekas}},
  howpublished = {https://web.mit.edu/dimitrib/www/RLbook.html},
  keywords = {math-thesis}
}

@article{duanRLFastReinforcement2016,
  title = {{{RL}}\$\^2\$: {{Fast Reinforcement Learning}} via {{Slow Reinforcement Learning}}},
  shorttitle = {{{RL}}\$\^2\$},
  author = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L. and Sutskever, Ilya and Abbeel, Pieter},
  year = {2016},
  month = nov,
  abstract = {Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a "fast" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL\$\^2\$, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose ("slow") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the "fast" RL algorithm on the current (previously unseen) MDP. We evaluate RL\$\^2\$ experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL\$\^2\$ is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL\$\^2\$ on a vision-based navigation task and show that it scales up to high-dimensional problems.},
  archiveprefix = {arXiv},
  eprint = {1611.02779},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\642IFFSG\\Duan et al_2016_RL$^2$.pdf;E\:\\Zotero\\storage\\B2I53VWE\\1611.html},
  journal = {arXiv:1611.02779 [cs, stat]},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,math-thesis,math-thesis:meta-learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@book{dudaPatternClassification2001,
  title = {Pattern Classification},
  author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
  year = {2001},
  edition = {2nd ed},
  publisher = {{Wiley}},
  address = {{New York}},
  file = {E\:\\Zotero\\storage\\5QBPNT52\\Solution_Duda et al_2001_Pattern classification.pdf;E\:\\Zotero\\storage\\8Z3SY63Z\\Chinese_Duda et al_2001_Pattern classification.pdf;E\:\\Zotero\\storage\\JAFZMMGK\\Duda et al_2001_Pattern classification.pdf},
  isbn = {978-0-471-05669-0},
  keywords = {Pattern recognition systems,Statistical decision},
  lccn = {Q327 .D83 2001}
}

@inproceedings{finnMetaLearningUniversalityDeep2018,
  title = {Meta-{{Learning}} and {{Universality}}: {{Deep Representations}} and {{Gradient Descent}} Can {{Approximate}} Any {{Learning Algorithm}}},
  shorttitle = {Meta-{{Learning}} and {{Universality}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Finn, Chelsea and Levine, Sergey},
  year = {2018},
  month = feb,
  abstract = {Deep representations combined with gradient descent can approximate any learning algorithm.},
  file = {E\:\\Zotero\\storage\\5SAM5LAZ\\Finn_Levine_2018_Meta-Learning and Universality.pdf;E\:\\Zotero\\storage\\2NTPBBPZ\\forum.html},
  keywords = {math-thesis},
  language = {en}
}

@inproceedings{finnModelagnosticMetalearningFast2017,
  title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  year = {2017},
  pages = {1126--1135},
  publisher = {{PMLR}},
  file = {E\:\\Zotero\\storage\\4DDA95ZN\\Finn et al_2017_Model-agnostic meta-learning for fast adaptation of deep networks.pdf;E\:\\Zotero\\storage\\BWSJT4RS\\finn17a.html},
  keywords = {_to_do,math-thesis}
}

@inproceedings{gaonReinforcementLearningNonMarkovian2020,
  title = {Reinforcement {{Learning}} with {{Non}}-{{Markovian Rewards}}},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Gaon, Maor and Brafman, Ronen},
  year = {2020},
  volume = {34},
  pages = {3980--3987},
  file = {E\:\\Zotero\\storage\\KFBZUCXU\\Gaon_Brafman_2020_Reinforcement Learning with Non-Markovian Rewards.pdf;E\:\\Zotero\\storage\\ZAG6MLRS\\5814.html},
  keywords = {_have_read,_to_do}
}

@article{gemanStochasticRelaxationGibbs1984,
  title = {Stochastic {{Relaxation}}, {{Gibbs Distributions}}, and the {{Bayesian Restoration}} of {{Images}}},
  author = {Geman, S. and Geman, D.},
  year = {1984},
  month = nov,
  volume = {PAMI-6},
  pages = {721--741},
  issn = {1939-3539},
  doi = {10/bpv4j5},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  file = {E\:\\Zotero\\storage\\6AGK7YTP\\Geman_Geman_1984_Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of.pdf;E\:\\Zotero\\storage\\H766ZCYD\\4767596.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Additive noise,Annealing,Bayesian methods,Deformable models,Degradation,Energy states,Gibbs distribution,image restoration,Image restoration,line process,MAP estimate,Markov random field,Markov random fields,relaxation,scene modeling,spatial degradation,Stochastic processes,Temperature distribution},
  number = {6}
}

@article{goldwaserDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} for {{General Game Playing}}},
  author = {Goldwaser, Adrian and Thielscher, Michael},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {1701--1708},
  issn = {2374-3468},
  doi = {10/ghtstj},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
  file = {E\:\\Zotero\\storage\\VW62JKGI\\Goldwaser_Thielscher_2020_Deep Reinforcement Learning for General Game Playing.pdf;E\:\\Zotero\\storage\\65YNNWKV\\5533.html},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  keywords = {_to_do,AAAI,AAAI 2020,math-thesis},
  language = {en},
  number = {02}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  file = {E\:\\Zotero\\storage\\4ZI38LM4\\Goodfellow et al_2016_Deep learning.pdf;E\:\\Zotero\\storage\\PV23UX6I\\Deep Learning.pdf},
  isbn = {978-0-262-03561-3},
  keywords = {_to_read,Machine learning,math-thesis,math-thesis:book},
  lccn = {Q325.5 .G66 2016},
  series = {Adaptive Computation and Machine Learning}
}

@inproceedings{goodfellowGenerativeAdversarialNets2014,
  ids = {goodfellowGenerativeAdversarialNets},
  title = {Generative {{Adversarial Nets}}},
  booktitle = {{{NIPS}}},
  author = {Goodfellow, Ian J. and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron C. and Bengio, Yoshua},
  year = {2014},
  file = {E\:\\Zotero\\storage\\CT4GVSEU\\Goodfellow et al_Generative Adversarial Nets.pdf;E\:\\Zotero\\storage\\X32MC5YK\\forum.html},
  keywords = {_have_read}
}

@inproceedings{guContinuousDeepQlearning2016,
  title = {Continuous Deep Q-Learning with Model-Based Acceleration},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  year = {2016},
  pages = {2829--2838},
  publisher = {{PMLR}},
  file = {E\:\\Zotero\\storage\\XNJZVI4H\\Gu et al_2016_Continuous deep q-learning with model-based acceleration.pdf;E\:\\Zotero\\storage\\8CX8N37M\\gu16.html}
}

@article{hastingsMonteCarloSampling1970,
  title = {Monte {{Carlo}} Sampling Methods Using {{Markov}} Chains and Their Applications},
  author = {Hastings, W. K.},
  year = {1970},
  month = apr,
  volume = {57},
  pages = {97--109},
  issn = {0006-3444},
  doi = {10/dkbmcf},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  file = {E\:\\Zotero\\storage\\JU4MRI5R\\Hastings_1970_Monte Carlo sampling methods using Markov chains and their applications.pdf;E\:\\Zotero\\storage\\WNW3WYQI\\284580.html},
  journal = {Biometrika},
  keywords = {math-thesis,math-thesis:classic},
  number = {1}
}

@article{heAutoMLSurveyStateoftheArt2020,
  title = {{{AutoML}}: {{A Survey}} of the {{State}}-of-the-{{Art}}},
  shorttitle = {{{AutoML}}},
  author = {He, Xin and Zhao, Kaiyong and Chu, Xiaowen},
  year = {2020},
  month = jul,
  abstract = {Deep learning (DL) techniques have penetrated all aspects of our lives and brought us great convenience. However, building a high-quality DL system for a specific task highly relies on human expertise, hindering the applications of DL to more areas. Automated machine learning (AutoML) becomes a promising solution to build a DL system without human assistance, and a growing number of researchers focus on AutoML. In this paper, we provide a comprehensive and up-to-date review of the state-of-the-art (SOTA) in AutoML. First, we introduce AutoML methods according to the pipeline, covering data preparation, feature engineering, hyperparameter optimization, and neural architecture search (NAS). We focus more on NAS, as it is currently very hot sub-topic of AutoML. We summarize the performance of the representative NAS algorithms on the CIFAR-10 and ImageNet datasets and further discuss several worthy studying directions of NAS methods: one/two-stage NAS, one-shot NAS, and joint hyperparameter and architecture optimization. Finally, we discuss some open problems of the existing AutoML methods for future research.},
  archiveprefix = {arXiv},
  eprint = {1908.00709},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\DU6LFC8K\\He et al. - 2020 - AutoML A Survey of the State-of-the-Art.pdf;E\:\\Zotero\\storage\\IWSC8NH2\\He et al_2020_AutoML.pdf;E\:\\Zotero\\storage\\RS5DEZQU\\1908.html},
  journal = {arXiv:1908.00709 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@book{hennessyComputerArchitectureQuantitative2019,
  title = {Computer Architecture: A Quantitative Approach},
  shorttitle = {Computer Architecture},
  author = {Hennessy, John L.},
  year = {2019},
  edition = {Sixth edition},
  publisher = {{Morgan Kaufmann Publishers}},
  address = {{Cambridge, MA}},
  file = {E\:\\Zotero\\storage\\ABN3AGQT\\Hennessy_2019_Computer architecture.pdf},
  isbn = {978-0-12-811905-1},
  keywords = {Computer architecture},
  lccn = {QA76.9.A73 P377 2019}
}

@article{hesselRainbowCombiningImprovements2018,
  title = {Rainbow: {{Combining Improvements}} in {{Deep Reinforcement Learning}}},
  shorttitle = {Rainbow},
  author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  year = {2018},
  month = apr,
  volume = {32},
  issn = {2374-3468},
  copyright = {Copyright (c)},
  file = {E\:\\Zotero\\storage\\7LMC3E3R\\Hessel et al_2018_Rainbow.pdf;E\:\\Zotero\\storage\\36YMFG3F\\11796.html},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  keywords = {deep reinforcement learning,math-thesis},
  language = {en},
  number = {1}
}

@article{hindmanMesosPlatformFineGrained,
  title = {Mesos: {{A Platform}} for {{Fine}}-{{Grained Resource Sharing}} in the {{Data Center}}},
  author = {Hindman, Benjamin and Konwinski, Andy and Zaharia, Matei and Ghodsi, Ali and Joseph, Anthony D and Katz, Randy and Shenker, Scott and Stoica, Ion},
  pages = {14},
  abstract = {We present Mesos, a platform for sharing commodity clusters between multiple diverse cluster computing frameworks, such as Hadoop and MPI. Sharing improves cluster utilization and avoids per-framework data replication. Mesos shares resources in a fine-grained manner, allowing frameworks to achieve data locality by taking turns reading data stored on each machine. To support the sophisticated schedulers of today's frameworks, Mesos introduces a distributed two-level scheduling mechanism called resource offers. Mesos decides how many resources to offer each framework, while frameworks decide which resources to accept and which computations to run on them. Our results show that Mesos can achieve near-optimal data locality when sharing the cluster among diverse frameworks, can scale to 50,000 (emulated) nodes, and is resilient to failures.},
  file = {E\:\\Zotero\\storage\\ZNQCJ394\\Hindman et al. - Mesos A Platform for Fine-Grained Resource Sharin.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@misc{hindupurHindupuravinashTheganzoo2021,
  title = {Hindupuravinash/the-Gan-Zoo},
  author = {Hindupur, Avinash},
  year = {2021},
  month = jan,
  abstract = {A list of all named GANs! Contribute to hindupuravinash/the-gan-zoo development by creating an account on GitHub.},
  copyright = {MIT License         ,                 MIT License},
  keywords = {gan,generative-adversarial-network,machine-learning}
}

@article{hoMoreEffectiveDistributed2013,
  title = {More Effective Distributed Ml via a Stale Synchronous Parallel Parameter Server},
  author = {Ho, Qirong and Cipar, James and Cui, Henggang and Kim, Jin Kyu and Lee, Seunghak and Gibbons, Phillip B. and Gibson, Garth A. and Ganger, Gregory R. and Xing, Eric P.},
  year = {2013},
  volume = {2013},
  pages = {1223},
  publisher = {{NIH Public Access}},
  file = {E\:\\Zotero\\storage\\P4EMRBEY\\Ho et al_2013_More effective distributed ml via a stale synchronous parallel parameter server.pdf;E\:\\Zotero\\storage\\G3MPLLH2\\PMC4230489.html},
  journal = {Advances in neural information processing systems},
  keywords = {_have_read}
}

@book{houjieSGISTLYuanMaPouXiXiangZhuanJiaXueXiXingBieJiShu2002,
  title = {{SGI STL源码剖析: 向专家学习型别技术, 内存管理, 算法, 数据结构, STL各类组件之高阶实现技巧 = The annotated STL sources}},
  shorttitle = {{SGI STL源码剖析}},
  author = {{侯捷}},
  year = {2002},
  annotation = {OCLC: 1109346036},
  file = {E\:\\Zotero\\storage\\BTGKBAX2\\侯捷_2002_SGI STL源码剖析.pdf},
  isbn = {978-7-5609-2699-5},
  language = {Chinese}
}

@misc{HungyiLee,
  title = {Hung-Yi {{Lee}}},
  file = {E\:\\Zotero\\storage\\747P79NA\\courses_ML20.html},
  howpublished = {http://speech.ee.ntu.edu.tw/\textasciitilde tlkagk/courses\_ML20.html}
}

@inproceedings{imamuraFairHymImprovingInterProcess2020,
  title = {{{FairHym}}: {{Improving Inter}}-{{Process Fairness}} on {{Hybrid Memory Systems}}},
  shorttitle = {{{FairHym}}},
  booktitle = {2020 9th {{Non}}-{{Volatile Memory Systems}} and {{Applications Symposium}} ({{NVMSA}})},
  author = {Imamura, Satoshi and Yoshida, Eiji},
  year = {2020},
  month = aug,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Seoul, Korea (South)}},
  doi = {10/ghrq2g},
  abstract = {Persistent memory (PMEM) is an emerging byteaddressable memory device that sits on a memory bus like conventional DRAM. A first PMEM product, Intel\textregistered{} Optane\texttrademark{} DC Persistent Memory (DCPM), has a larger capacity and lower cost per gigabyte than DRAM, although its performance is lower than that of DRAM. Therefore, hybrid memory systems that combine DRAM and DCPM for main memory are recommended to take advantage of both of them. However, our previous work revealed significant unfairness between two processes co-running on a real hybrid memory system; the performance of a process accessing DRAM is significantly degraded by another performing frequent writes to DCPM, but not vice versa.},
  file = {E\:\\Zotero\\storage\\MCQQHEPC\\Imamura and Yoshida - 2020 - FairHym Improving Inter-Process Fairness on Hybri.pdf},
  isbn = {978-1-72818-482-1},
  language = {en}
}

@misc{irpanDeepReinforcementLearning2018,
  title = {Deep {{Reinforcement Learning Doesn}}'t {{Work Yet}}},
  author = {{Irpan} and {Alex}},
  year = {2018},
  abstract = {June 24, 2018 note: If you want to cite an example from the post, please cite the paper which that example came from. If you want to cite the post as a whole, you can use the following BibTeX:},
  file = {E\:\\Zotero\\storage\\T4PK3I9W\\rl-hard.html},
  howpublished = {http://www.alexirpan.com/2018/02/14/rl-hard.html},
  keywords = {math-thesis}
}

@inproceedings{jeonAnalysisLargescaleMultitenant2019,
  ids = {jeonAnalysisLargeScaleMultiTenant,jeonAnalysisLargeScaleMultiTenant2020},
  title = {Analysis of Large-Scale Multi-Tenant \$\{\$\vphantom\}{{GPU}}\$\vphantom\{\}\$ Clusters for \$\{\$\vphantom\}{{DNN}}\$\vphantom\{\}\$ Training Workloads},
  booktitle = {2019 \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Annual Technical Conference}} (\$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$\$\{\$\vphantom\}{{ATC}}\$\vphantom\{\}\$ 19)},
  author = {Jeon, Myeongjae and Venkataraman, Shivaram and Phanishayee, Amar and Qian, Junjie and Xiao, Wencong and Yang, Fan},
  year = {2019},
  pages = {947--960},
  file = {E\:\\Zotero\\storage\\3W86MSIH\\Jeon et al. - Analysis of Large-Scale Multi-Tenant GPU Clusters .pdf;E\:\\Zotero\\storage\\ETDJ45AC\\Jeon et al. - Analysis of Large-Scale Multi-Tenant GPU Clusters .pdf;E\:\\Zotero\\storage\\FAKYYTNL\\Jeon et al_2019_Analysis of large-scale multi-tenant $ $GPU$ $ clusters for $ $DNN$ $ training.pdf;E\:\\Zotero\\storage\\J3VI3DBE\\Jeon et al. - 2019 - Analysis of large-scale multi-tenant $ $GPU$ $ clu.pdf;E\:\\Zotero\\storage\\IRYI4G49\\jeon.html;E\:\\Zotero\\storage\\VIJTA9VW\\jeon.html},
  keywords = {⛔ No DOI found}
}

@article{jeonMultitenantGpuClusters2018,
  ids = {jeonMultitenantGPUClusters2018},
  title = {Multi-Tenant Gpu Clusters for Deep Learning Workloads: {{Analysis}} and Implications},
  shorttitle = {Multi-Tenant Gpu Clusters for Deep Learning Workloads},
  author = {Jeon, Myeongjae and Venkataraman, Shivaram and Qian, Junjie and Phanishayee, Amar and Xiao, Wencong and Yang, Fan},
  year = {2018},
  file = {E\:\\Zotero\\storage\\K5XGQ93C\\Jeon et al_2018_Multi-tenant gpu clusters for deep learning workloads.pdf},
  journal = {Technical report, Microsoft Research},
  keywords = {⛔ No DOI found}
}

@inproceedings{jiangUnifiedArchitectureAccelerating2020,
  title = {A {{Unified Architecture}} for {{Accelerating Distributed}} \{\vphantom\}{{DNN}}\vphantom\{\} {{Training}} in {{Heterogeneous GPU}}/{{CPU Clusters}}},
  booktitle = {14th \{\vphantom\}{{USENIX}}\vphantom\{\} {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\{\vphantom\}{{OSDI}}\vphantom\{\} 20)},
  author = {Jiang, Yimin and Zhu, Yibo and Lan, Chang and Yi, Bairen and Cui, Yong and Guo, Chuanxiong},
  year = {2020},
  pages = {463--479},
  file = {E\:\\Zotero\\storage\\JAZYPU7J\\Jiang et al_2020_A Unified Architecture for Accelerating Distributed DNN Training in.pdf;E\:\\Zotero\\storage\\WN6M8TB7\\Jiang et al. - A Uniﬁed Architecture for Accelerating Distributed.pdf;E\:\\Zotero\\storage\\P3E9EVFV\\jiang.html},
  isbn = {978-1-939133-19-9},
  keywords = {_have_read},
  language = {en}
}

@inproceedings{kadekodiSplitFSReducingSoftware2019,
  title = {{{SplitFS}}: Reducing Software Overhead in File Systems for Persistent Memory},
  shorttitle = {{{SplitFS}}},
  booktitle = {Proceedings of the 27th {{ACM Symposium}} on {{Operating Systems Principles}}},
  author = {Kadekodi, Rohan and Lee, Se Kwon and Kashyap, Sanidhya and Kim, Taesoo and Kolli, Aasheesh and Chidambaram, Vijay},
  year = {2019},
  month = oct,
  pages = {494--508},
  publisher = {{ACM}},
  address = {{Huntsville Ontario Canada}},
  doi = {10/ggb32t},
  abstract = {We present SplitFS, a file system for persistent memory (PM) that reduces software overhead significantly compared to state-of-the-art PM file systems. SplitFS presents a novel split of responsibilities between a user-space library file system and an existing kernel PM file system. The user-space library file system handles data operations by intercepting POSIX calls, memory-mapping the underlying file, and serving the read and overwrites using processor loads and stores. Metadata operations are handled by the kernel PM file system (ext4 DAX). SplitFS introduces a new primitive termed relink to efficiently support file appends and atomic data operations. SplitFS provides three consistency modes, which different applications can choose from, without interfering with each other. SplitFS reduces software overhead by up-to 4\texttimes{} compared to the NOVA PM file system, and 17\texttimes{} compared to ext4 DAX. On a number of micro-benchmarks and applications such as the LevelDB key-value store running the YCSB benchmark, SplitFS increases application performance by up to 2\texttimes{} compared to ext4 DAX and NOVA while providing similar consistency guarantees.},
  file = {E\:\\Zotero\\storage\\4P5A796M\\Kadekodi et al. - 2019 - SplitFS reducing software overhead in file system.pdf},
  isbn = {978-1-4503-6873-5},
  language = {en}
}

@book{kerriskLinuxProgrammingInterface2010,
  title = {The {{Linux}} Programming Interface: A {{Linux}} and {{UNIX}} System Programming Handbook},
  shorttitle = {The {{Linux}} Programming Interface},
  author = {Kerrisk, Michael},
  year = {2010},
  publisher = {{No Starch Press}},
  address = {{San Francisco}},
  file = {E\:\\Zotero\\storage\\9NAAV3VE\\Kerrisk - 2010 - The Linux programming interface a Linux and UNIX .pdf},
  isbn = {978-1-59327-220-3},
  keywords = {Linux,Operating systems (Computers),UNIX (Computer file)},
  language = {en},
  lccn = {QA76.76.O63 K496 2010}
}

@inproceedings{kimMLayerLowLatency2019,
  title = {{{$\mu$Layer}}: {{Low Latency On}}-{{Device Inference Using Cooperative Single}}-{{Layer Acceleration}} and {{Processor}}-{{Friendly Quantization}}},
  shorttitle = {{{$\mu$Layer}}},
  booktitle = {Proceedings of the {{Fourteenth EuroSys Conference}} 2019},
  author = {Kim, Youngsok and Kim, Joonsung and Chae, Dongju and Kim, Daehyun and Kim, Jangwoo},
  year = {2019},
  month = mar,
  pages = {1--15},
  publisher = {{ACM}},
  address = {{Dresden Germany}},
  doi = {10/ghrqwd},
  file = {E\:\\Zotero\\storage\\QUFN7J4X\\Kim et al. - 2019 - μLayer Low Latency On-Device Inference Using Coop.pdf},
  isbn = {978-1-4503-6281-8},
  keywords = {_have_read},
  language = {en}
}

@article{kingmaAdamMethodStochastic2015,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  author = {Kingma, Diederik P and Lei, Jimmy},
  year = {2015},
  pages = {15},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  file = {E\:\\Zotero\\storage\\HVRCMH7N\\Kingma_Lei_2015_Adam.pdf},
  keywords = {_no_read,⛔ No DOI found},
  language = {en}
}

@article{kingmaAutoEncodingVariationalBayes2014,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  year = {2014},
  month = may,
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  archiveprefix = {arXiv},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\S7NAIPAT\\Kingma and Welling - 2014 - Auto-Encoding Variational Bayes.pdf;E\:\\Zotero\\storage\\VDKH79YL\\Tutorials of Variational Bayesian Inference.pdf},
  journal = {arXiv:1312.6114 [cs, stat]},
  keywords = {_have_read,⛔ No DOI found,Computer Science - Machine Learning,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{kingmaGlowGenerativeFlow,
  title = {Glow: {{Generative Flow}} with {{Invertible}} 1\$\textbackslash times\$ 1 {{Convolutions}}},
  shorttitle = {Glow},
  author = {Kingma, Diederik P. and Dhariwal, Prafulla},
  file = {E\:\\Zotero\\storage\\AGGHJER4\\Kingma_Dhariwal_Glow.pdf}
}

@inproceedings{kirschImprovingGeneralizationMeta2019,
  title = {Improving {{Generalization}} in {{Meta Reinforcement Learning}} Using {{Learned Objectives}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, Juergen},
  year = {2019},
  month = sep,
  abstract = {We introduce MetaGenRL, a novel meta reinforcement learning algorithm. Unlike prior work, MetaGenRL can generalize to new environments that are entirely different from those used for meta-training.},
  file = {E\:\\Zotero\\storage\\FKI2NYJY\\Kirsch et al_2019_Improving Generalization in Meta Reinforcement Learning using Learned Objectives.pdf;E\:\\Zotero\\storage\\IMMCVVAB\\forum.html},
  keywords = {math-thesis},
  language = {en}
}

@inproceedings{laffertyConditionalRandomFields2001a,
  title = {Conditional {{Random Fields}}: {{Probabilistic Models}} for {{Segmenting}} and {{Labeling Sequence Data}}},
  shorttitle = {Conditional {{Random Fields}}},
  booktitle = {Proceedings of the {{Eighteenth International Conference}} on {{Machine Learning}}},
  author = {Lafferty, John D. and McCallum, Andrew and Pereira, Fernando C. N.},
  year = {2001},
  month = jun,
  pages = {282--289},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  address = {{San Francisco, CA, USA}},
  file = {E\:\\Zotero\\storage\\LIVK9AEK\\Lafferty et al_2001_Conditional Random Fields.pdf},
  isbn = {978-1-55860-778-1},
  series = {{{ICML}} '01}
}

@inproceedings{langfordSlowLearnersAre2009a,
  title = {Slow Learners Are Fast},
  booktitle = {Proceedings of the 22nd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Langford, John and Smola, Alexander J. and Zinkevich, Martin},
  year = {2009},
  month = dec,
  pages = {2331--2339},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  abstract = {Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning.},
  file = {E\:\\Zotero\\storage\\U6943SXY\\Langford et al_2009_Slow Learners are Fast.pdf},
  isbn = {978-1-61567-911-9},
  series = {{{NIPS}}'09}
}

@book{lanyizhongGaoDengDaiShuJianMingJiaoChengShang2007,
  title = {{高等代数简明教程（上）}},
  author = {{蓝以中}},
  year = {2007},
  publisher = {{北京大学出版社}},
  address = {{北京}},
  annotation = {OCLC: 909244033},
  file = {E\:\\Zotero\\storage\\JZCLG4T4\\蓝以中_2007_高等代数简明教程(上).pdf},
  isbn = {978-7-301-05370-6},
  language = {Chinese}
}

@book{lanyizhongGaoDengDaiShuJianMingJiaoChengXia2007,
  title = {{高等代数简明教程（下）}},
  author = {{蓝以中}},
  year = {2007},
  publisher = {{北京大学出版社}},
  address = {{北京}},
  annotation = {OCLC: 909244033},
  file = {E\:\\Zotero\\storage\\D8SSEPGR\\蓝以中_2007_高等代数简明教程(下).pdf},
  isbn = {978-7-301-05579-3},
  language = {Chinese}
}

@article{lattnerMLIRCompilerInfrastructure2020,
  title = {{{MLIR}}: {{A Compiler Infrastructure}} for the {{End}} of {{Moore}}'s {{Law}}},
  shorttitle = {{{MLIR}}},
  author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  year = {2020},
  month = feb,
  abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, significantly reduce the cost of building domain specific compilers, and aid in connecting existing compilers together.},
  archiveprefix = {arXiv},
  eprint = {2002.11054},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\YTW7HXF4\\Lattner et al. - 2020 - MLIR A Compiler Infrastructure for the End of Moo.pdf},
  journal = {arXiv:2002.11054 [cs]},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,Computer Science - Programming Languages},
  language = {en},
  primaryclass = {cs}
}

@inproceedings{lavinFastAlgorithmsConvolutional2016,
  title = {Fast {{Algorithms}} for {{Convolutional Neural Networks}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Lavin, Andrew and Gray, Scott},
  year = {2016},
  month = jun,
  pages = {4013--4021},
  publisher = {{IEEE}},
  address = {{Las Vegas, NV, USA}},
  doi = {10/ggwcc2},
  abstract = {Deep convolutional neural networks take GPU-days of computation to train on large data sets. Pedestrian detection for self driving cars requires very low latency. Image recognition for mobile phones is constrained by limited processing resources. The success of convolutional neural networks in these situations is limited by how fast we can compute them. Conventional FFT based convolution is fast for large filters, but state of the art convolutional neural networks use small, 3 \texttimes{} 3 filters. We introduce a new class of fast algorithms for convolutional neural networks using Winograd's minimal filtering algorithms. The algorithms compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes. We benchmark a GPU implementation of our algorithm with the VGG network and show state of the art throughput at batch sizes from 1 to 64.},
  file = {E\:\\Zotero\\storage\\NKDTE8RP\\Lavin and Gray - 2016 - Fast Algorithms for Convolutional Neural Networks.pdf},
  isbn = {978-1-4673-8851-1},
  keywords = {CVPR},
  language = {en}
}

@misc{LeeMengJinJiDeBERT,
  title = {{{LeeMeng}} - 進擊的 {{BERT}}：{{NLP}} 界的巨人之力與遷移學習},
  howpublished = {https://leemeng.tw/attack\_on\_bert\_transfer\_learning\_in\_nlp.html}
}

@article{leeStochasticLatentActorCritic2020,
  title = {Stochastic {{Latent Actor}}-{{Critic}}: {{Deep Reinforcement Learning}} with a {{Latent Variable Model}}},
  shorttitle = {Stochastic {{Latent Actor}}-{{Critic}}},
  author = {Lee, Alex and Nagabandi, Anusha and Abbeel, Pieter and Levine, Sergey},
  year = {2020},
  volume = {33},
  file = {E\:\\Zotero\\storage\\DTABJEZC\\Lee et al_2020_Stochastic Latent Actor-Critic.pdf;E\:\\Zotero\\storage\\DG9VA3BZ\\08058bf500242562c0d031ff830ad094-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {_to_do,NeurIPS,NeurIPS 2020},
  language = {en}
}

@article{liangxingxingDuoAgentShenDuQiangHuaXueXiZongShu2020,
  title = {{{多Agent深度强化学习综述}}},
  author = {梁星星 and 冯旸赫 and 马扬 and 程光权 and 黄金才 and 王琦 and 周玉珍 and 刘忠},
  year = {2020},
  month = dec,
  volume = {46},
  pages = {2537--2557},
  publisher = {{自动化学报}},
  issn = {0254-4156},
  doi = {10/ghtss2},
  file = {E\:\\Zotero\\storage\\78C2967R\\梁星星 et al_2020_多Agent深度强化学习综述.pdf;E\:\\Zotero\\storage\\6AUD8VVX\\j.aas.html},
  journal = {自动化学报},
  number = {12}
}

@book{lidongfengTongJiJiSuanStatisticalComputing2017,
  title = {{统计计算 = Statistical computing}},
  author = {{李东风}},
  year = {2017},
  publisher = {{高等教育出版社}},
  address = {{北京}},
  abstract = {Ben shu jiang shu tong ji ji suan de ji ben gai nian he tong ji ji suan zhong zui chang yong de suan fa,Nei rong han gai le wu cha,Miao shu tong ji,Sui ji shu chan sheng,Sui ji mo ni,Bi jin,Cha zhi,Shu zhi ji fen yu shu zhi wei fen,Ju zhen ji suan,Zui you hua yu fang cheng qiu gen deng ge ge fang mian.},
  annotation = {OCLC: 1082555188},
  file = {E\:\\Zotero\\storage\\D8NSM3WG\\李东风_2017_统计计算 = Statistical computing.pdf},
  isbn = {978-7-04-047070-3},
  language = {Chinese}
}

@book{lihangTongJiXueXiFangFa2012,
  title = {{统计学习方法}},
  author = {{李航}},
  year = {2012},
  annotation = {OCLC: 1104438334},
  file = {E\:\\Zotero\\storage\\X88PG7HF\\李航_2012_统计学习方法.pdf},
  isbn = {978-7-302-27595-4},
  keywords = {_no_read},
  language = {Chinese}
}

@book{lihangTongJiXueXiFangFa2019,
  title = {{统计学习方法}},
  author = {{李航}},
  year = {2019},
  publisher = {{清华大学出版社}},
  address = {{北京}},
  abstract = {Ben shu fen wei jian du xue xi he wu jian du xue xi liang pian,Xi tong di jie shao le tong ji xue xi de zhu yao fang fa.Bao kuo gan zhi ji,k jin lin fa,Po su bei ye si fa,Jue ce shu,Luo ji si di hui gui yu zui da shang mo xing,Zhi chi xiang liang ji,Ti sheng fang fa,EM suan fa,Yin ma er ke fu mo xing he tiao jian sui ji chang,Yi ji ju lei fang fa,Qi yi zhi fen jie,Zhu cheng fen fen xi,Qian zai yu yi fen xi,Gai l\"u qian zai yu yi fen xi,Ma er ke fu lian meng te ka luo fa,Qian zai di li ke lei fen pei he PageRank suan fa deng.},
  annotation = {OCLC: 1178828718},
  file = {E\:\\Zotero\\storage\\76N7YUKI\\李航_2019_统计学习方法.pdf},
  isbn = {978-7-302-51727-6},
  language = {Chinese}
}

@article{lillicrapContinuousControlDeep2019,
  title = {Continuous Control with Deep Reinforcement Learning},
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  year = {2019},
  month = jul,
  abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies ``end-to-end'': directly from raw pixel inputs.},
  archiveprefix = {arXiv},
  eprint = {1509.02971},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\YNS694HC\\Lillicrap et al. - 2019 - Continuous control with deep reinforcement learning.pdf},
  journal = {arXiv:1509.02971 [cs, stat]},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,math-thesis,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{liMultitaskBatchReinforcement,
  title = {Multi-Task {{Batch Reinforcement Learning}} with {{Metric Learning}}},
  author = {Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  pages = {14},
  abstract = {We tackle the Multi-task Batch Reinforcement Learning problem. Given multiple datasets collected from different tasks, we train a multi-task policy to perform well in unseen tasks sampled from the same distribution. The task identities of the unseen tasks are not provided. To perform well, the policy must infer the task identity from collected transitions by modelling its dependency on states, actions and rewards. Because the different datasets may have state-action distributions with large divergence, the task inference module can learn to ignore the rewards and spuriously correlate only state-action pairs to the task identity, leading to poor test time performance. To robustify task inference, we propose a novel application of the triplet loss. To mine hard negative examples, we relabel the transitions from the training tasks by approximating their reward functions. When we allow further training on the unseen tasks, using the trained policy as an initialization leads to significantly faster convergence compared to randomly initialized policies (up to 80\% improvement and across 5 different Mujoco task distributions). We name our method MBML (Multi-task Batch RL with Metric Learning) 2.},
  file = {E\:\\Zotero\\storage\\A7VDUAQR\\Li et al. - Multi-task Batch Reinforcement Learning with Metri.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@inproceedings{liScalingDistributedMachine2014,
  title = {Scaling {{Distributed Machine Learning}} with the {{Parameter Server}}},
  booktitle = {Proceedings of the 2014 {{International Conference}} on {{Big Data Science}} and {{Computing}} - {{BigDataScience}} '14},
  author = {Li, Mu},
  year = {2014},
  pages = {1--1},
  publisher = {{ACM Press}},
  address = {{Beijing, China}},
  doi = {10/ggp59g},
  abstract = {We propose a parameter server framework for distributed machine learning problems. Both data and workloads are distributed over worker nodes, while the server nodes maintain globally shared parameters, represented as dense or sparse vectors and matrices. The framework manages asynchronous data communication between nodes, and supports flexible consistency models, elastic scalability, and continuous fault tolerance.},
  file = {E\:\\Zotero\\storage\\YS9EZ8R7\\Li - 2014 - Scaling Distributed Machine Learning with the Para.pdf},
  isbn = {978-1-4503-2891-3},
  keywords = {_to_read},
  language = {en}
}

@book{liTongJiJiSuan,
  title = {统计计算},
  author = {LI, Dongfeng},
  abstract = {本科生《统计计算》教材，采用R语言和Julia语言，包括误差、随机数生成、随机模拟、近似计算、矩阵计算、最优化，主要介绍算法而不是软件中的程序包用法。采用R的bookdown制作，输出格式为bookdown::gitbook.},
  file = {E\:\\Zotero\\storage\\K6HVMRRV\\index.html}
}

@article{liujianweiJiYuZhiHanShuHeCeLueTiDuDeShenDuQiangHuaXueXiZongShu2019,
  title = {基于值函数和策略梯度的深度强化学习综述},
  author = {{刘建伟} and {高峰} and {罗雄麟}},
  year = {2019},
  volume = {42},
  pages = {1406--1438},
  publisher = {{中国计算机学会| 中国科学院计算技术研究所}},
  file = {E\:\\Zotero\\storage\\7YF2GNRV\\刘建伟 et al_2019_基于值函数和策略梯度的深度强化学习综述.pdf},
  journal = {计算机学报},
  keywords = {_to_do,math-thesis},
  number = {6}
}

@article{liuVARIANCEADAPTIVELEARNING2020,
  title = {{{ON THE VARIANCE OF THE ADAPTIVE LEARNING RATE AND BEYOND}}},
  author = {Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
  year = {2020},
  pages = {13},
  file = {E\:\\Zotero\\storage\\94UWND87\\Liu et al_2020_ON THE VARIANCE OF THE ADAPTIVE LEARNING RATE AND BEYOND.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@book{lixianpingGaiLuLunJiChu2010,
  title = {{概率论基础}},
  author = {{李贤平}},
  year = {2010},
  annotation = {OCLC: 1105863188},
  file = {E\:\\Zotero\\storage\\S4QQ3B3Y\\李贤平_2010_概率论基础.pdf},
  isbn = {978-7-04-028890-2},
  language = {Chinese}
}

@article{luoADAPTIVEGRADIENTMETHODS2019,
  title = {{{ADAPTIVE GRADIENT METHODS WITH DYNAMIC BOUND OF LEARNING RATE}}},
  author = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
  year = {2019},
  pages = {21},
  abstract = {Adaptive optimization methods such as ADAGRAD, RMSPROP and ADAM have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. Though prevailing, they are observed to generalize poorly compared with SGD or even fail to converge due to unstable and extreme learning rates. Recent work has put forward some algorithms such as AMSGRAD to tackle this issue but they failed to achieve considerable improvement over existing methods. In our paper, we demonstrate that extreme learning rates can lead to poor performance. We provide new variants of ADAM and AMSGRAD, called ADABOUND and AMSBOUND respectively, which employ dynamic bounds on learning rates to achieve a gradual and smooth transition from adaptive methods to SGD and give a theoretical proof of convergence. We further conduct experiments on various popular tasks and models, which is often insufficient in previous work. Experimental results show that new variants can eliminate the generalization gap between adaptive methods and SGD and maintain higher learning speed early in training at the same time. Moreover, they can bring significant improvement over their prototypes, especially on complex deep networks. The implementation of the algorithm can be found at https://github.com/Luolc/AdaBound.},
  file = {E\:\\Zotero\\storage\\KRG74H5Z\\Luo et al_2019_ADAPTIVE GRADIENT METHODS WITH DYNAMIC BOUND OF LEARNING RATE.pdf},
  keywords = {_no_read,⛔ No DOI found},
  language = {en}
}

@inproceedings{maHeterogeneousCPUGPU2020,
  title = {Heterogeneous {{CPU}}+{{GPU Stochastic Gradient Descent Algorithms}}},
  booktitle = {{{arXiv}}:2004.08771 [Cs]},
  author = {Ma, Yujing and Rusu, Florin},
  year = {2020},
  month = apr,
  abstract = {The widely-adopted practice is to train deep learning models with specialized hardware accelerators, e.g., GPUs or TPUs, due to their superior performance on linear algebra operations. However, this strategy does not employ effectively the extensive CPU and memory resources \textendash{} which are used only for preprocessing, data transfer, and scheduling \textendash{} available by default on the accelerated servers. In this paper, we study training algorithms for deep learning on heterogeneous CPU+GPU architectures. Our two-fold objective \textendash{} maximize convergence rate and resource utilization simultaneously \textendash{} makes the problem challenging. In order to allow for a principled exploration of the design space, we first introduce a generic deep learning framework that exploits the difference in computational power and memory hierarchy between CPU and GPU through asynchronous message passing. Based on insights gained through experimentation with the framework, we design two heterogeneous asynchronous stochastic gradient descent (SGD) algorithms. The first algorithm \textendash{} CPU+GPU Hogbatch \textendash{} combines small batches on CPU with large batches on GPU in order to maximize the utilization of both resources. However, this generates an unbalanced model update distribution which hinders the statistical convergence. The second algorithm \textendash{} Adaptive Hogbatch \textendash{} assigns batches with continuously evolving size based on the relative speed of CPU and GPU. This balances the model updates ratio at the expense of a customizable decrease in utilization. We show that the implementation of these algorithms in the proposed CPU+GPU framework achieves both faster convergence and higher resource utilization than TensorFlow on several real datasets and on two computing architectures\textemdash an on-premises server and a cloud instance.},
  archiveprefix = {arXiv},
  eprint = {2004.08771},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\6JNE7TCT\\Ma and Rusu - 2020 - Heterogeneous CPU+GPU Stochastic Gradient Descent .pdf},
  keywords = {_to_read,⛔ No DOI found,Computer Science - Databases,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning},
  language = {en},
  primaryclass = {cs}
}

@book{maoshisongBeiYeSiTongJi2012,
  title = {{贝叶斯统计}},
  author = {{茆诗松} and {汤银才}},
  year = {2012},
  annotation = {OCLC: 1104201980},
  file = {E\:\\Zotero\\storage\\AFYYUUXY\\Solution_茆诗松_汤银才_2012_贝叶斯统计.pdf;E\:\\Zotero\\storage\\CH553X9W\\茆诗松_汤银才_2012_贝叶斯统计.pdf},
  isbn = {978-7-5037-6692-3},
  language = {Chinese}
}

@book{maoshisongGaoDengShuLiTongJiAdvancedMathematical2006,
  title = {{高等数理统计 = Advanced mathematical statistics}},
  author = {{茆诗松} and {王静龙} and {濮晓龙}},
  year = {2006},
  annotation = {OCLC: 1109045616},
  file = {E\:\\Zotero\\storage\\AYUEI4AD\\茆诗松 et al_2006_高等数理统计 = Advanced mathematical statistics.pdf},
  isbn = {978-7-04-019321-3},
  language = {Chinese}
}

@inproceedings{maRammerEnablingHolistic2020,
  ids = {maRAMMEREnablingHolistic},
  title = {Rammer: {{Enabling Holistic Deep Learning Compiler Optimizations}} with {{rTasks}}},
  shorttitle = {Rammer},
  booktitle = {14th \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\$\{\$\vphantom\}{{OSDI}}\$\vphantom\{\}\$ 20)},
  author = {Ma, Lingxiao and Xie, Zhiqiang and Yang, Zhi and Xue, Jilong and Miao, Youshan and Cui, Wei and Hu, Wenxiang and Yang, Fan and Zhang, Lintao and Zhou, Lidong},
  year = {2020},
  pages = {881--897},
  file = {E\:\\Zotero\\storage\\BJ3UHZHV\\Ma et al. - RAMMER Enabling Holistic Deep Learning Compiler O.pdf;E\:\\Zotero\\storage\\MRQQ4A9V\\Ma et al_RAMMER.pdf;E\:\\Zotero\\storage\\K8XYBQYL\\ma.html},
  keywords = {⛔ No DOI found}
}

@book{mauererProfessionalLinuxKernel2008,
  title = {Professional {{Linux}} Kernel Architecture},
  author = {Mauerer, Wolfgang},
  year = {2008},
  publisher = {{Wiley Pub}},
  address = {{Indianapolis, IN}},
  annotation = {OCLC: ocn227198266},
  file = {E\:\\Zotero\\storage\\6CAJPJM6\\Mauerer_2008_Professional Linux kernel architecture.pdf},
  isbn = {978-0-470-34343-2},
  keywords = {Application software,Computer architecture,Linux},
  lccn = {QA76.9.A73 M38 2008},
  series = {Wrox Professional Guides}
}

@article{MetaLearningComputer2021,
  title = {Meta Learning (Computer Science)},
  year = {2021},
  month = feb,
  abstract = {Meta learning is a subfield of machine learning where automatic learning algorithms are applied to metadata about machine learning experiments. As of 2017 the term had not found a standard interpretation, however the main goal is to use such metadata to understand how automatic learning can become flexible in solving learning problems, hence to improve the performance of existing learning algorithms or to learn (induce) the learning algorithm itself, hence the alternative term learning to learn.Flexibility is important because each learning algorithm is based on a set of assumptions about the data, its inductive bias. This means that it will only learn well if the bias matches the learning problem. A learning algorithm may perform very well in one domain, but not on the next. This poses strong restrictions on the use of machine learning or data mining techniques, since the relationship between the learning problem (often some kind of database) and the effectiveness of different learning algorithms is not yet understood. By using different kinds of metadata, like properties of the learning problem, algorithm properties (like performance measures), or patterns previously derived from the data, it is possible to learn, select, alter or combine different learning algorithms to effectively solve a given learning problem. Critiques of meta learning approaches bear a strong resemblance to the critique of metaheuristic, a possibly related problem. A good analogy to meta-learning, and the inspiration for J\"urgen Schmidhuber's early work (1987) and Yoshua Bengio et al.'s work (1991), considers that genetic evolution learns the learning procedure encoded in genes and executed in each individual's brain. In an open-ended hierarchical meta learning system using genetic programming, better evolutionary methods can be learned by meta evolution, which itself can be improved by meta meta evolution, etc.},
  annotation = {Page Version ID: 1006135814},
  copyright = {Creative Commons Attribution-ShareAlike License},
  file = {E\:\\Zotero\\storage\\BMDVBC3R\\index.html},
  journal = {Wikipedia},
  keywords = {math-thesis},
  language = {en}
}

@article{MianXiangDaShuJuChuLiDeJiYuSparkDeYiZhiNeiCunBianChengKuangJia2018,
  title = {面向大数据处理的基于 {{Spark}} 的异质内存编程框架},
  year = {2018},
  doi = {10.7544/issn1000-1239.2018.20170687},
  abstract = {随着大数据应用的发展，需要处理的数据量急剧增长，企业为了保证数据的及时处理并快速响应客户，正在广泛部署以Apache Spark为代表的内存计算系统.然而TB级别的内存不但造成了服务器成本的上升，也促进了功耗的增长.由于DRAM的功耗、容量密度受限于工艺瓶颈，无法满足内存计算快速增长的内存需求，因此研发人员将目光逐渐移向了新型的非易失性内存(non-volatile memory, NVM).由DRAM和NVM共同构成的异质内存，具有低成本、低功耗、高容量密度等特点，但由于NVM读写性能较差，如何合理布局数据到异质内存是一个关键的研究问题.系统分析了Spark应用的访存特征，并结合OpenJDK的内存使用特点，提出了一套管理数据在DRAM和NVM之间布局的编程框架.应用开发者通过对本文提供接口的简单调用，便可将数据合理布局在异质内存之中.仅需20\%\textasciitilde 25\%的DRAM和大量的NVM，便可以达到使用等量的DRAM时90\%左右的性能.该框架可以通过有效利用异质内存来满足内存计算不断增长的计算规模.同时，``性能/价格''比仅用DRAM时提高了数倍.},
  file = {E\:\\Zotero\\storage\\4JINAD22\\面向大数据处理的基于 Spark 的异质内存编程框架.pdf}
}

@article{michaelPositiveNegativeReinforcement1975,
  ids = {michaelPositiveNegativeReinforcement1975a},
  title = {Positive and {{Negative Reinforcement}}, a {{Distinction That Is No Longer Necessary}}; {{Or}} a {{Better Way}} to {{Talk}} about {{Bad Things}}},
  author = {Michael, Jack},
  year = {1975},
  volume = {3},
  pages = {33--44},
  publisher = {{Cambridge Center for Behavioral Studies (CCBS)}},
  issn = {0090-4155},
  journal = {Behaviorism},
  keywords = {⛔ No DOI found,math-thesis},
  number = {1}
}

@article{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\MHQ47AEY\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf},
  journal = {arXiv:1301.3781 [cs]},
  keywords = {_no_read,⛔ No DOI found,Computer Science - Computation and Language},
  language = {en},
  primaryclass = {cs}
}

@inproceedings{mnihAsynchronousMethodsDeep2016,
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  year = {2016},
  month = jun,
  pages = {1928--1937},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present as...},
  file = {E\:\\Zotero\\storage\\IENIJIMW\\Mnih et al_2016_Asynchronous Methods for Deep Reinforcement Learning.pdf;E\:\\Zotero\\storage\\I7XEBD4Z\\mniha16.html},
  keywords = {_to_do,math-thesis,math-thesis:classic},
  language = {en}
}

@article{mnihHumanlevelControlDeep2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg},
  year = {2015},
  volume = {518},
  pages = {529--533},
  publisher = {{Nature Publishing Group}},
  doi = {10/gc3h75},
  file = {E\:\\Zotero\\storage\\P8TR5G3V\\Mnih et al_2015_Human-level control through deep reinforcement learning.pdf;E\:\\Zotero\\storage\\MJAR3N24\\nature14236.html},
  journal = {nature},
  keywords = {math-thesis},
  number = {7540}
}

@article{mnihPlayingAtariDeep2013,
  title = {Playing {{Atari}} with {{Deep Reinforcement Learning}}},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  year = {2013},
  month = dec,
  abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  archiveprefix = {arXiv},
  eprint = {1312.5602},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\VG77NEXA\\Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf},
  journal = {arXiv:1312.5602 [cs]},
  keywords = {_to_do,⛔ No DOI found,Computer Science - Machine Learning,math-thesis,NeurIPS,NeurIPS 2013},
  language = {en},
  primaryclass = {cs}
}

@book{moerleShenRuLinuxNeiHeJiaGou2010,
  title = {{深入Linux内核架构}},
  author = {{莫尔勒} and {郭旭}},
  year = {2010},
  publisher = {{人民邮电出版社}},
  address = {{北京}},
  abstract = {Ben shu tao lun le Linux nei he de gai nian, Jie gou he shi xian. Zhu yao nei rong bao kuo duo ren wu, Diao du he jin cheng guan li, Wu li nei cun de guan li yi ji nei he yu xiang guan ying jian de jiao hu, Yong hu kong jian de jin cheng ru he fang wen xu ni nei cun, Ru he bian xie she bei qu dong cheng xu, Mo kuai ji zhi yi ji xu ni wen jian xi tong, Ext wen jian xi tong shu xing he fang wen kong zhi biao de shi xian fang shi, Nei he zhong wang luo de shi xian, Xi tong diao yong de shi xian fang shi, Nei he dui shi jian xiang guan gong neng de chu li, Ye mian hui shou he ye jiao huan de xiang guan ji zhi yi ji shen ji de shi xian deng.},
  annotation = {OCLC: 678905282},
  file = {E\:\\Zotero\\storage\\T64JAGMU\\莫尔勒 and 郭旭 - 2010 - 深入Linux内核架构.pdf},
  isbn = {978-7-115-22743-0},
  language = {Chinese}
}

@inproceedings{narasimhanLanguageUnderstandingTextbased2015,
  title = {Language {{Understanding}} for {{Text}}-Based {{Games}} Using {{Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 2015 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Narasimhan, Karthik and Kulkarni, Tejas and Barzilay, Regina},
  year = {2015},
  pages = {1--11},
  doi = {10/ght9db},
  file = {E\:\\Zotero\\storage\\MTXA933T\\Narasimhan et al_2015_Language Understanding for Text-based Games using Deep Reinforcement Learning.pdf},
  keywords = {math-thesis}
}

@book{naumannArtDifferentiatingComputer2011,
  title = {The {{Art}} of {{Differentiating Computer Programs}}: {{An Introduction}} to {{Algorithmic Differentiation}}},
  shorttitle = {The {{Art}} of {{Differentiating Computer Programs}}},
  author = {Naumann, Uwe},
  year = {2011},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972078},
  abstract = {Deep learning software demands reliability and performance. However, many of the existing deep learning frameworks are software libraries that act as an unsafe DSL in Python and a computation graph interpreter, some with inefficient algorithmic differentiation by operator overloading. We present DLVM, a design and implementation of a compiler infrastructure with a linear algebra intermediate representation, algorithmic differentiation by adjoint code generation, domainspecific optimizations and a code generator targeting GPU via LLVM. Designed as a modern compiler framework inspired by LLVM, DLVM is more modular and more generic than existing deep learning compiler frameworks, and supports tensor DSLs with high expressivity. We argue that the DLVM system enables a form of modular, safe and performant frameworks for deep learning.},
  file = {E\:\\Zotero\\storage\\7E3PSXGL\\Naumann - 2011 - The Art of Differentiating Computer Programs An I.pdf},
  isbn = {978-1-61197-206-1 978-1-61197-207-8},
  language = {en}
}

@inproceedings{neubigDyNetDynamicNeural2017,
  title = {{{DyNet}}: {{The Dynamic Neural Network Toolkit}}},
  shorttitle = {{{DyNet}}},
  booktitle = {{{arXiv}}:1701.03980 [Cs, Stat]},
  author = {Neubig, Graham and Dyer, Chris and Goldberg, Yoav and Matthews, Austin and Ammar, Waleed and Anastasopoulos, Antonios and Ballesteros, Miguel and Chiang, David and Clothiaux, Daniel and Cohn, Trevor and Duh, Kevin and Faruqui, Manaal and Gan, Cynthia and Garrette, Dan and Ji, Yangfeng and Kong, Lingpeng and Kuncoro, Adhiguna and Kumar, Gaurav and Malaviya, Chaitanya and Michel, Paul and Oda, Yusuke and Richardson, Matthew and Saphra, Naomi and Swayamdipta, Swabha and Yin, Pengcheng},
  year = {2017},
  month = jan,
  abstract = {We describe DyNet, a toolkit for implementing neural network models based on dynamic declaration of network structure. In the static declaration strategy that is used in toolkits like Theano, CNTK, and TensorFlow, the user first defines a computation graph (a symbolic representation of the computation), and then examples are fed into an engine that executes this computation and computes its derivatives. In DyNet's dynamic declaration strategy, computation graph construction is mostly transparent, being implicitly constructed by executing procedural code that computes the network outputs, and the user is free to use different network structures for each input. Dynamic declaration thus facilitates the implementation of more complicated network architectures, and DyNet is specifically designed to allow users to implement their models in a way that is idiomatic in their preferred programming language (C++ or Python). One challenge with dynamic declaration is that because the symbolic computation graph is defined anew for every training example, its construction must have low overhead. To achieve this, DyNet has an optimized C++ backend and lightweight graph representation. Experiments show that DyNet's speeds are faster than or comparable with static declaration toolkits, and significantly faster than Chainer, another dynamic declaration toolkit. DyNet is released opensource under the Apache 2.0 license, and available at http://github.com/clab/dynet.},
  archiveprefix = {arXiv},
  eprint = {1701.03980},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\LTZWR57E\\Neubig et al. - 2017 - DyNet The Dynamic Neural Network Toolkit.pdf},
  keywords = {⛔ No DOI found,Computer Science - Computation and Language,Computer Science - Mathematical Software,Statistics - Machine Learning},
  language = {en},
  primaryclass = {cs, stat}
}

@article{nguyenDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} for {{Multi}}-{{Agent Systems}}: {{A Review}} of {{Challenges}}, {{Solutions}} and {{Applications}}},
  shorttitle = {Deep {{Reinforcement Learning}} for {{Multi}}-{{Agent Systems}}},
  author = {Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
  year = {2020},
  month = sep,
  volume = {50},
  pages = {3826--3839},
  issn = {2168-2267, 2168-2275},
  doi = {10/gg2f37},
  abstract = {Reinforcement learning (RL) algorithms have been around for decades and employed to solve various sequential decision-making problems. These algorithms however have faced great challenges when dealing with high-dimensional environments. The recent development of deep learning has enabled RL methods to drive optimal policies for sophisticated and capable agents, which can perform efficiently in these challenging environments. This paper addresses an important aspect of deep RL related to situations that require multiple agents to communicate and cooperate to solve complex tasks. A survey of different approaches to problems related to multi-agent deep RL (MADRL) is presented, including non-stationarity, partial observability, continuous state and action spaces, multi-agent training schemes, multi-agent transfer learning. The merits and demerits of the reviewed methods will be analyzed and discussed, with their corresponding applications explored. It is envisaged that this review provides insights about various MADRL methods and can lead to future development of more robust and highly useful multi-agent learning methods for solving real-world problems.},
  archiveprefix = {arXiv},
  eprint = {1812.11794},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\KVQ2AKIF\\Nguyen et al. - 2020 - Deep Reinforcement Learning for Multi-Agent System.pdf},
  journal = {IEEE Transactions on Cybernetics},
  keywords = {_to_do,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Multiagent Systems,Statistics - Machine Learning},
  language = {en},
  number = {9}
}

@article{nianReviewReinforcementLearning2020,
  ids = {nianReviewReinforcementLearning2020a},
  title = {A Review {{On}} Reinforcement Learning: {{Introduction}} and Applications in Industrial Process Control},
  shorttitle = {A Review {{On}} Reinforcement Learning},
  author = {Nian, Rui and Liu, Jinfeng and Huang, Biao},
  year = {2020},
  month = aug,
  volume = {139},
  pages = {106886},
  issn = {0098-1354},
  doi = {10/ghtr6p},
  abstract = {In recent years, reinforcement learning (RL) has attracted significant attention from both industry and academia due to its success in solving some complex problems. This paper provides an overview of RL along with tutorials for practitioners who are interested in implementing RL solutions into process control applications. The paper starts by providing an introduction to different reinforcement learning algorithms. Then, recent successes of RL applications across different industries will be explored, with more emphasis on process control applications. A detailed RL implementation example will also be shown. Afterwards, RL will be compared with traditional optimal control methods, in terms of stability and computational complexity among other factors, and the current shortcomings of RL will be introduced. This paper is concluded with a summary of RL's potential advantages and disadvantages.},
  file = {E\:\\Zotero\\storage\\RYJ3TTP8\\Nian et al_2020_A review On reinforcement learning.pdf;E\:\\Zotero\\storage\\SJG6EARV\\Nian et al_2020_A review On reinforcement learning.pdf;E\:\\Zotero\\storage\\JNASPP7G\\S0098135420300557.html;E\:\\Zotero\\storage\\LD4LMESE\\S0098135420300557.html},
  journal = {Computers \& Chemical Engineering},
  keywords = {_to_do,Machine learning,Model predictive control,Optimal control,Process control,Process industry,Reinforcement learning},
  language = {en}
}

@article{NOTICESRECENTPUBLICATIONS1928,
  title = {{{NOTICES OF RECENT PUBLICATIONS}}},
  year = {1928},
  month = mar,
  volume = {51},
  pages = {129--130},
  issn = {0006-8950},
  doi = {10/dcs8bc},
  file = {E\:\\Zotero\\storage\\JPMCWEDM\\1928_NOTICES OF RECENT PUBLICATIONS.pdf;E\:\\Zotero\\storage\\B8G4GQBC\\268769.html},
  journal = {Brain},
  number = {1}
}

@article{NVShuffleJiYuFeiYiShiNeiCunDeShuffleJiZhi2018,
  title = {{{NV}}-{{Shuffle}}: {{基于非易失内存的Shuffle机制}}},
  year = {2018},
  file = {E\:\\Zotero\\storage\\ZT3F256C\\NV-Shuffle.pdf}
}

@article{ohDiscoveringReinforcementLearning2020,
  title = {Discovering {{Reinforcement Learning Algorithms}}},
  author = {Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M. and Xu, Zhongwen and {van Hasselt}, Hado P. and Singh, Satinder and Silver, David},
  year = {2020},
  volume = {33},
  file = {E\:\\Zotero\\storage\\9GQ8VJGQ\\Oh et al_2020_Discovering Reinforcement Learning Algorithms.pdf;E\:\\Zotero\\storage\\K928L6BS\\Supplemental.pdf;E\:\\Zotero\\storage\\CSAP33BJ\\0b96d81f0494fde5428c7aea243c9157-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {_have_read,_to_do,math-thesis,NeurIPS,NeurIPS 2020},
  language = {en}
}

@inproceedings{osbandBehaviourSuiteReinforcement2019,
  title = {Behaviour {{Suite}} for {{Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Osband, Ian and Doron, Yotam and Hessel, Matteo and Aslanides, John and Sezener, Eren and Saraiva, Andre and McKinney, Katrina and Lattimore, Tor and Szepesvari, Csaba and Singh, Satinder and Roy, Benjamin Van and Sutton, Richard and Silver, David and Hasselt, Hado Van},
  year = {2019},
  month = sep,
  abstract = {Bsuite is a collection of carefully-designed experiments that investigate the core capabilities of RL agents.},
  file = {E\:\\Zotero\\storage\\WLDRZUCR\\Osband et al_2019_Behaviour Suite for Reinforcement Learning.pdf;E\:\\Zotero\\storage\\UL24Z8CA\\forum.html},
  keywords = {math-thesis},
  language = {en}
}

@book{ouModernTutorial11,
  title = {Modern {{C}}++ {{Tutorial}}: {{C}}++11/14/17/20 {{On}} the {{Fly}}},
  author = {Ou, Changkun},
  file = {E\:\\Zotero\\storage\\66MPHAMR\\Ou_Modern C++ Tutorial-zh.pdf;E\:\\Zotero\\storage\\ESBRXDNR\\Ou - Modern C++ Tutorial C++11141720 On the Fly.pdf},
  keywords = {⛔ No DOI found}
}

@book{paqiefuShenRuLiJieMySQLHeXinJiShu2009,
  title = {{深入理解MySQL核心技术}},
  author = {{帕切夫} and {李芳} and {于红芸} and {邵健}},
  year = {2009},
  publisher = {{中国电力出版社}},
  address = {{北京}},
  abstract = {Ben shu fen 12 zhang, Nei rong bao kuo:MySQL de li shi yu jia gou, MySQL yuan dai ma ji ben yao dian, Ke hu duan/ fu wu qi tong xin, Pei zhi bian liang, Ji yu xian cheng de qing qiu chu li deng.},
  annotation = {OCLC: 601603507},
  file = {E\:\\Zotero\\storage\\4C5VFULH\\帕切夫 et al_2009_深入理解MySQL核心技术.pdf},
  isbn = {978-7-5083-8790-1},
  language = {Chinese}
}

@inproceedings{parkHetPipeEnablingLarge2020,
  title = {{{HetPipe}}: {{Enabling Large}} \{\vphantom\}{{DNN}}\vphantom\{\} {{Training}} on ({{Whimpy}}) {{Heterogeneous}} \{\vphantom\}{{GPU}}\vphantom\{\} {{Clusters}} through {{Integration}} of {{Pipelined Model Parallelism}} and {{Data Parallelism}}},
  shorttitle = {{{HetPipe}}},
  booktitle = {2020 \{\vphantom\}{{USENIX}}\vphantom\{\} {{Annual Technical Conference}} (\{\vphantom\}{{USENIX}}\vphantom\{\} \{\vphantom\}{{ATC}}\vphantom\{\} 20)},
  author = {Park, Jay H. and Yun, Gyeongchan and Yi, Chang M. and Nguyen, Nguyen T. and Lee, Seungmin and Choi, Jaesik and Noh, Sam H. and Choi, Young-ri},
  year = {2020},
  pages = {307--321},
  file = {E\:\\Zotero\\storage\\AGTNA8FV\\Park et al_2020_HetPipe.pdf;E\:\\Zotero\\storage\\BPBSNPFV\\park.html},
  isbn = {978-1-939133-14-4},
  keywords = {_have_read,_to_read},
  language = {en}
}

@inproceedings{paszkeAutomaticDifferentiationPyTorch2017,
  title = {Automatic Differentiation in {{PyTorch}}},
  booktitle = {31st {{Conference}} on {{Neural Information Processing Systems}} ({{NIPS}} 2017)},
  author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year = {2017},
  pages = {4},
  abstract = {In this article, we describe an automatic differentiation module of PyTorch \textemdash{} a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
  file = {E\:\\Zotero\\storage\\CJABPZ5Q\\Paszke et al. - Automatic differentiation in PyTorch.pdf},
  keywords = {_reading,⛔ No DOI found},
  language = {en}
}

@inproceedings{paszkePytorchImperativeStyle2019,
  title = {Pytorch: {{An}} Imperative Style, High-Performance Deep Learning Library},
  shorttitle = {Pytorch},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca},
  year = {2019},
  pages = {8026--8037},
  file = {E\:\\Zotero\\storage\\226XNCYE\\Paszke et al_2019_Pytorch.pdf;E\:\\Zotero\\storage\\L2C472B3\\bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
  keywords = {_have_read}
}

@inproceedings{pengGenericCommunicationScheduler2019,
  title = {A Generic Communication Scheduler for Distributed {{DNN}} Training Acceleration},
  booktitle = {Proceedings of the 27th {{ACM Symposium}} on {{Operating Systems Principles}}},
  author = {Peng, Yanghua and Zhu, Yibo and Chen, Yangrui and Bao, Yixin and Yi, Bairen and Lan, Chang and Wu, Chuan and Guo, Chuanxiong},
  year = {2019},
  month = oct,
  pages = {16--29},
  publisher = {{ACM}},
  address = {{Huntsville Ontario Canada}},
  doi = {10/ggv8zk},
  abstract = {We present ByteScheduler, a generic communication scheduler for distributed DNN training acceleration. ByteScheduler is based on our principled analysis that partitioning and rearranging the tensor transmissions can result in optimal results in theory and good performance in real-world even with scheduling overhead. To make ByteScheduler work generally for various DNN training frameworks, we introduce a unified abstraction and a Dependency Proxy mechanism to enable communication scheduling without breaking the original dependencies in framework engines. We further introduce a Bayesian Optimization approach to auto-tune tensor partition size and other parameters for different training models under various networking conditions. ByteScheduler now supports TensorFlow, PyTorch, and MXNet without modifying their source code, and works well with both Parameter Server (PS) and all-reduce architectures for gradient synchronization, using either TCP or RDMA. Our experiments show that ByteScheduler accelerates training with all experimented system configurations and DNN models, by up to 196\% (or 2.96\texttimes{} of original speed).},
  file = {E\:\\Zotero\\storage\\K7R63AYU\\Peng et al. - 2019 - A generic communication scheduler for distributed .pdf},
  isbn = {978-1-4503-6873-5},
  keywords = {_have_read},
  language = {en}
}

@article{petersDeepContextualizedWord2018,
  title = {Deep Contextualized Word Representations},
  author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  year = {2018},
  month = mar,
  abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
  archiveprefix = {arXiv},
  eprint = {1802.05365},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\XDUDY9EI\\Peters et al_2018_Deep contextualized word representations.pdf;E\:\\Zotero\\storage\\GZMUF4C3\\1802.html},
  journal = {arXiv:1802.05365 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryclass = {cs}
}

@article{pfauConnectingGenerativeAdversarial2017,
  ids = {pfauConnectingGenerativeAdversarial2017a},
  title = {Connecting {{Generative Adversarial Networks}} and {{Actor}}-{{Critic Methods}}},
  author = {Pfau, David and Vinyals, Oriol},
  year = {2017},
  month = jan,
  abstract = {Both generative adversarial networks (GAN) in unsupervised learning and actor-critic methods in reinforcement learning (RL) have gained a reputation for being difficult to optimize. Practitioners in both fields have amassed a large number of strategies to mitigate these instabilities and improve training. Here we show that GANs can be viewed as actor-critic methods in an environment where the actor cannot affect the reward. We review the strategies for stabilizing training for each class of models, both those that generalize between the two and those that are particular to that model. We also review a number of extensions to GANs and RL algorithms with even more complicated information flow. We hope that by highlighting this formal connection we will encourage both GAN and RL communities to develop general, scalable, and stable algorithms for multilevel optimization with deep networks, and to draw inspiration across communities.},
  archiveprefix = {arXiv},
  eprint = {1610.01945},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\FA86E3T5\\Pfau_Vinyals_2017_Connecting Generative Adversarial Networks and Actor-Critic Methods.pdf;E\:\\Zotero\\storage\\GAJESBWN\\Pfau_Vinyals_2017_Connecting Generative Adversarial Networks and Actor-Critic Methods.pdf;E\:\\Zotero\\storage\\3D9IATH6\\1610.html;E\:\\Zotero\\storage\\U4I4SN2Q\\1610.html},
  journal = {arXiv:1610.01945 [cs, stat]},
  keywords = {_to_do,⛔ No DOI found,Computer Science - Machine Learning,math-thesis,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{pudipeddiTrainingLargeNeural2020,
  title = {Training {{Large Neural Networks}} with {{Constant Memory}} Using a {{New Execution Algorithm}}},
  author = {Pudipeddi, Bharadwaj and Mesmakhosroshahi, Maral and Xi, Jinwen and Bharadwaj, Sujeeth},
  year = {2020},
  month = jun,
  abstract = {Widely popular transformer-based NLP models such as BERT and Turing-NLG have enormous capacity trending to billions of parameters. Current execution methods demand brute-force resources such as HBM devices and high speed interconnectivity for data parallelism. In this paper, we introduce a new relay-style execution technique called L2L (layer-to-layer) where at any given moment, the device memory is primarily populated only with the executing layer(s)'s footprint. The model resides in the DRAM memory attached to either a CPU or an FPGA as an entity we call eager param-server (EPS). To overcome the bandwidth issues of shuttling parameters to and from EPS, the model is executed a layer at a time across many micro-batches instead of the conventional method of minibatches over whole model. L2L is implemented using 16GB V100 devices for BERT-Large running it with a device batch size of up to 256. Our results show 45\% reduction in memory and 40\% increase in the throughput compared to the state-of-the-art baseline. L2L is also able to fit models up to 50 Billion parameters on a machine with a single 16GB V100 and 512GB CPU memory and without requiring any model partitioning. L2L scales to arbitrary depth allowing researchers to develop on affordable devices which is a big step toward democratizing AI. By running the optimizer in the host EPS, we show a new form of mixed precision for faster throughput and convergence. In addition, the EPS enables dynamic neural architecture approaches by varying layers across iterations. Finally, we also propose and demonstrate a constant memory variation of L2L and we propose future enhancements. This work has been performed on GPUs first, but also targeted towards all high TFLOPS/Watt accelerators.},
  archiveprefix = {arXiv},
  eprint = {2002.05645},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\LKLCGK98\\Pudipeddi et al_2020_Training Large Neural Networks with Constant Memory using a New Execution.pdf;E\:\\Zotero\\storage\\ZBXXK3RS\\2002.html},
  journal = {arXiv:2002.05645 [cs, stat]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@article{puVariationalAutoencoderDeep2016,
  title = {Variational Autoencoder for Deep Learning of Images, Labels and Captions},
  author = {Pu, Yunchen and Gan, Zhe and Henao, Ricardo and Yuan, Xin and Li, Chunyuan and Stevens, Andrew and Carin, Lawrence},
  year = {2016},
  volume = {29},
  pages = {2352--2360},
  file = {E\:\\Zotero\\storage\\WRE9H8J8\\Pu et al_2016_Variational autoencoder for deep learning of images, labels and captions.pdf;E\:\\Zotero\\storage\\2JT83CNH\\eb86d510361fc23b59f18c1bc9802cc6-Abstract.html},
  journal = {Advances in neural information processing systems}
}

@article{QiangHuaXueXi2021,
  title = {{强化学习}},
  year = {2021},
  month = mar,
  abstract = {强化学习（英语：Reinforcement learning，简称RL）是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。与监督学习不同的是，强化学习不需要带标签的输入输出对，同时也无需对非最优解的精确地纠正。其关注点在于寻找探索（对未知领域的）和利用（对已有知识的）的平衡，强化学习中的``探索-利用''的交换，在多臂老虎机问题和有限MDP中研究得最多。。 其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。这个方法具有普适性，因此在其他许多领域都有研究，例如博弈论、控制论、运筹学、信息论、仿真优化、多智能体系统、群体智能、统计学以及遗传算法。在运筹学和控制理论研究的语境下，强化学习被称作``近似动态规划''（approximate dynamic programming，ADP）。在最优控制理论中也有研究这个问题，虽然大部分的研究是关于最优解的存在和特性，并非是学习或者近似方面。在经济学和博弈论中，强化学习被用来解释在有限理性的条件下如何出现平衡。 在机器学习问题中，环境通常被抽象为马尔可夫决策过程（Markov decision processes，MDP），因为很多强化学习算法在这种假设下才能使用动态规划的方法。传统的动态规划方法和强化学习算法的主要区别是，后者不需要关于MDP的知识，而且针对无法找到确切方法的大规模MDP。},
  annotation = {Page Version ID: 64889694},
  copyright = {Creative Commons Attribution-ShareAlike License},
  file = {E\:\\Zotero\\storage\\WBVWBDF8\\index.html},
  journal = {维基百科，自由的百科全书},
  keywords = {math-thesis},
  language = {zh-Hans-CN}
}

@book{qianxieziLiangZhouZiZhiJiaoBenYuYan2014,
  title = {{两周自制脚本语言}},
  author = {{千葉滋}},
  year = {2014},
  annotation = {OCLC: 1049560886},
  file = {E\:\\Zotero\\storage\\ZSATL2C3\\千葉滋 - 2014 - 两周自制脚本语言.pdf},
  isbn = {978-7-115-35564-5},
  language = {zh}
}

@article{radfordUnsupervisedRepresentationLearning2016,
  title = {Unsupervised {{Representation Learning}} with {{Deep Convolutional Generative Adversarial Networks}}},
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  year = {2016},
  month = jan,
  abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  archiveprefix = {arXiv},
  eprint = {1511.06434},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\5JF6NWBY\\Radford et al_2016_Unsupervised Representation Learning with Deep Convolutional Generative.pdf;E\:\\Zotero\\storage\\NNBD8NMJ\\1511.html},
  journal = {arXiv:1511.06434 [cs]},
  keywords = {⛔ No DOI found,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  primaryclass = {cs}
}

@inproceedings{rajbhandariZeROMemoryOptimizations2020,
  title = {{{ZeRO}}: {{Memory}} Optimizations {{Toward Training Trillion Parameter Models}}},
  shorttitle = {{{ZeRO}}},
  booktitle = {{{SC20}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = nov,
  pages = {1--16},
  publisher = {{IEEE}},
  address = {{Atlanta, GA, USA}},
  doi = {10/gh559v},
  abstract = {Large deep learning models offer significant accuracy gains, but training billions to trillions of parameters is challenging. Existing solutions such as data and model parallelisms exhibit fundamental limitations to fit these models into limited device memory, while obtaining computation, communication and development efficiency. We develop a novel solution, Zero Redundancy Optimizer (ZeRO), to optimize memory, vastly improving training speed while increasing the model size that can be efficiently trained. ZeRO eliminates memory redundancies in data- and model-parallel training while retaining low communication volume and high computational granularity, allowing us to scale the model size proportional to the number of devices with sustained high efficiency. Our analysis on memory requirements and communication volume demonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters using today's hardware.},
  file = {E\:\\Zotero\\storage\\RIQ5I8JJ\\Rajbhandari et al. - 2020 - ZeRO Memory optimizations Toward Training Trillio.pdf},
  isbn = {978-1-72819-998-6},
  keywords = {_to_read,DeepSpeed,research},
  language = {en}
}

@inproceedings{rasleyDeepSpeedSystemOptimizations2020,
  title = {{{DeepSpeed}}: {{System Optimizations Enable Training Deep Learning Models}} with {{Over}} 100 {{Billion Parameters}}},
  shorttitle = {{{DeepSpeed}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = aug,
  pages = {3505--3506},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10/gh584s},
  abstract = {Explore new techniques in Microsoft's open source library called DeepSpeed, which advances large model training by improving scale, speed, cost, and usability, unlocking the ability to train 100-billion-parameter models. DeepSpeed is compatible with PyTorch. One piece of our library, called ZeRO, is a new parallelized optimizer that greatly reduces the resources needed for model and data parallelism while massively increasing the number of parameters that can be trained. Researchers have used these breakthroughs to create Turing Natural Language Generation (Turing-NLG), which at the time of its release was the largest publicly known language model at 17 billion parameters. In addition we will also go over our latest transformer kernel advancements that led the DeepSpeed team to achieve the world fastest BERT pretraining record. The Zero Redundancy Optimizer (ZeRO) is a novel memory optimization technology for large-scale distributed deep learning. ZeRO can train deep learning models with over 100 billion parameters on the current generation of GPU clusters at three to five times the throughput of the current best system. It also presents a clear path to training models with trillions of parameters, demonstrating an unprecedented leap in deep learning system technology. DeepSpeed brings state-of-the-art training techniques, such as ZeRO, optimized kernels, distributed training, mixed precision, and checkpointing, through lightweight APIs compatible with PyTorch. With just a few lines of code changes to your PyTorch model, you can leverage DeepSpeed to address underlying performance challenges and boost the speed and scale of your training.},
  file = {E\:\\Zotero\\storage\\V7PAIVU2\\Rasley et al_2020_DeepSpeed.pdf},
  isbn = {978-1-4503-7998-4},
  keywords = {DeepSpeed,distributed deep learning,machine learning},
  series = {{{KDD}} '20}
}

@article{reddiCONVERGENCEADAM2018,
  title = {{{ON THE CONVERGENCE OF ADAM AND BEYOND}}},
  author = {Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  year = {2018},
  pages = {23},
  abstract = {Several recently proposed stochastic optimization methods that have been successfully used in training deep networks such as RMSPROP, ADAM, ADADELTA, NADAM are based on using gradient updates scaled by square roots of exponential moving averages of squared past gradients. In many applications, e.g. learning with large output spaces, it has been empirically observed that these algorithms fail to converge to an optimal solution (or a critical point in nonconvex settings). We show that one cause for such failures is the exponential moving average used in the algorithms. We provide an explicit example of a simple convex optimization setting where ADAM does not converge to the optimal solution, and describe the precise problems with the previous analysis of ADAM algorithm. Our analysis suggests that the convergence issues can be fixed by endowing such algorithms with ``long-term memory'' of past gradients, and propose new variants of the ADAM algorithm which not only fix the convergence issues but often also lead to improved empirical performance.},
  file = {E\:\\Zotero\\storage\\LW9GQ4AJ\\Reddi et al_2018_ON THE CONVERGENCE OF ADAM AND BEYOND.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{ReinforcementLearning2021,
  title = {Reinforcement Learning},
  year = {2021},
  month = mar,
  abstract = {Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning. Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge). The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. The main difference between the classical dynamic programming methods  and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.},
  annotation = {Page Version ID: 1009612279},
  copyright = {Creative Commons Attribution-ShareAlike License},
  file = {E\:\\Zotero\\storage\\M6S3Z82F\\index.html},
  journal = {Wikipedia},
  keywords = {math-thesis},
  language = {en}
}

@misc{RenRenDuNengKanDongDeLSTM,
  title = {{人人都能看懂的LSTM}},
  abstract = {这是在看了台大李宏毅教授的深度学习视频之后的一点总结和感想。看完介绍的第一部分RNN尤其LSTM的介绍之后，整个人醍醐灌顶。本篇博客就是对视频的一些记录加上了一些个人的思考。0. 从RNN说起循环神经网络（Recur\ldots},
  file = {E\:\\Zotero\\storage\\LGEN5Y73\\32085405.html},
  howpublished = {https://zhuanlan.zhihu.com/p/32085405},
  journal = {知乎专栏},
  keywords = {math-thesis},
  language = {zh}
}

@article{renZeROOffloadDemocratizingBillionScale2021,
  title = {{{ZeRO}}-{{Offload}}: {{Democratizing Billion}}-{{Scale Model Training}}},
  shorttitle = {{{ZeRO}}-{{Offload}}},
  author = {Ren, Jie and Rajbhandari, Samyam and Aminabadi, Reza Yazdani and Ruwase, Olatunji and Yang, Shuangyan and Zhang, Minjia and Li, Dong and He, Yuxiong},
  year = {2021},
  month = jan,
  abstract = {Large-scale model training has been a playing ground for a limited few requiring complex model refactoring and access to prohibitively expensive GPU clusters. ZeRO-Offload changes the large model training landscape by making large model training accessible to nearly everyone. It can train models with over 13 billion parameters on a single GPU, a 10x increase in size compared to popular framework such as PyTorch, and it does so without requiring any model change from the data scientists or sacrificing computational efficiency. ZeRO-Offload enables large model training by offloading data and compute to CPU. To preserve compute efficiency, it is designed to minimize the data movement to/from GPU, and reduce CPU compute time while maximizing memory savings on GPU. As a result, ZeRO-Offload can achieve 40 TFlops/GPU on a single NVIDIA V100 GPU for 10B parameter model compared to 30TF using PyTorch alone for a 1.4B parameter model, the largest that can be trained without running out of memory. ZeRO-Offload is also designed to scale on multiple-GPUs when available, offering near linear speedup on up to 128 GPUs. Additionally, it can work together with model parallelism to train models with over 70 billion parameters on a single DGX-2 box, a 4.5x increase in model size compared to using model parallelism alone. By combining compute and memory efficiency with ease-of-use, ZeRO-Offload democratizes large-scale model training making it accessible to even data scientists with access to just a single GPU.},
  archiveprefix = {arXiv},
  eprint = {2101.06840},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\7C79R2BQ\\Ren et al_2021_ZeRO-Offload.pdf;E\:\\Zotero\\storage\\YRV6E35F\\2101.html},
  journal = {arXiv:2101.06840 [cs]},
  keywords = {_to_read,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,DeepSpeed,research},
  primaryclass = {cs}
}

@inproceedings{rhuVDNNVirtualizedDeep2016,
  title = {{{vDNN}}: {{Virtualized}} Deep Neural Networks for Scalable, Memory-Efficient Neural Network Design},
  shorttitle = {{{vDNN}}},
  booktitle = {2016 49th {{Annual IEEE}}/{{ACM International Symposium}} on {{Microarchitecture}} ({{MICRO}})},
  author = {Rhu, Minsoo and Gimelshein, Natalia and Clemons, Jason and Zulfiqar, Arslan and Keckler, Stephen W.},
  year = {2016},
  pages = {1--13},
  publisher = {{IEEE}},
  doi = {10/ghr7kg},
  archiveprefix = {arXiv},
  eprint = {1602.08124},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\9ZNLU5EN\\Rhu et al. - 2016 - vDNN Virtualized deep neural networks for scalabl.pdf;E\:\\Zotero\\storage\\BPZ9NQ8L\\Rhu et al. - 2016 - vDNN Virtualized Deep Neural Networks for Scalabl.pdf;E\:\\Zotero\\storage\\A9IIEEFE\\7783721.html},
  keywords = {_have_read,_to_read,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,vDNN}
}

@book{robertlovewujinyiLinuxXiTongBianCheng2009,
  title = {Linux 系统编程},
  author = {{ROBERT LOVE 吴晋(译)}},
  year = {2009},
  file = {E\:\\Zotero\\storage\\68LB3TCN\\Linux 系统编程.pdf}
}

@inproceedings{rothfussProMPProximalMetaPolicy2018,
  title = {{{ProMP}}: {{Proximal Meta}}-{{Policy Search}}},
  shorttitle = {{{ProMP}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter},
  year = {2018},
  month = sep,
  abstract = {A novel and theoretically grounded meta-reinforcement learning algorithm},
  file = {E\:\\Zotero\\storage\\TNIYEAGZ\\Rothfuss et al_2018_ProMP.pdf;E\:\\Zotero\\storage\\8LQBIJ6H\\forum.html},
  keywords = {math-thesis,math-thesis:meta-learning},
  language = {en}
}

@article{ruderOverviewGradientDescent2017,
  title = {An Overview of Gradient Descent Optimization Algorithms},
  author = {Ruder, Sebastian},
  year = {2017},
  month = jun,
  abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  archiveprefix = {arXiv},
  eprint = {1609.04747},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\97WJ6XN3\\Ruder - 2017 - An overview of gradient descent optimization algor.pdf},
  journal = {arXiv:1609.04747 [cs]},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning},
  language = {en},
  primaryclass = {cs}
}

@book{rudinRealComplexAnalysis1987,
  title = {Real and Complex Analysis},
  author = {Rudin, Walter},
  year = {1987},
  edition = {3rd ed},
  publisher = {{McGraw-Hill}},
  address = {{New York}},
  file = {E\:\\Zotero\\storage\\Y73UVV9D\\Rudin_1987_Real and complex analysis.pdf},
  isbn = {978-0-07-054234-1},
  language = {en},
  lccn = {QA300 .R82 1987}
}

@inproceedings{s.b.DynamicMemoryManagement2019,
  title = {Dynamic {{Memory Management}} for {{GPU}}-{{Based Training}} of {{Deep Neural Networks}}},
  booktitle = {2019 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {S.B., Shriram and Garg, Anshuj and Kulkarni, Purushottam},
  year = {2019},
  month = may,
  pages = {200--209},
  publisher = {{IEEE}},
  address = {{Rio de Janeiro, Brazil}},
  doi = {10/ghrqv4},
  abstract = {Deep learning has been widely adopted for different applications of artificial intelligence\textemdash speech recognition, natural language processing, computer vision etc. The growing size of Deep Neural Networks (DNNs) has compelled the researchers to design memory efficient and performance optimal algorithms. Apart from algorithmic improvements, specialized hardware like Graphics Processing Units (GPUs) are being widely employed to accelerate the training and inference phases of deep networks. However, the limited GPU memory capacity limits the upper bound on the size of networks that can be offloaded to and trained using GPUs. vDNN addresses the GPU memory bottleneck issue and provides a solution which enables training of deep networks that are larger than GPU memory. In our work, we characterize and identify multiple bottlenecks with vDNN like delayed computation start, high pinned memory requirements and GPU memory fragmentation. We present vDNN++ which extends vDNN and resolves the identified issues. Our results show that the performance of vDNN++ is comparable or better (up to 60\% relative improvement) than vDNN. We propose different heuristics and order for memory allocation, and empirically evaluate the extent of memory fragmentation with them. We are also able to reduce the pinned memory requirement by up to 60\%.},
  file = {E\:\\Zotero\\storage\\BTBCFBT9\\S.B. et al. - 2019 - Dynamic Memory Management for GPU-Based Training o.pdf},
  isbn = {978-1-72811-246-6},
  keywords = {_to_read,vDNN++},
  language = {en}
}

@article{sakLongShortTermMemory2014,
  title = {Long {{Short}}-{{Term Memory Based Recurrent Neural Network Architectures}} for {{Large Vocabulary Speech Recognition}}},
  author = {Sak, Ha{\c s}im and Senior, Andrew and Beaufays, Fran{\c c}oise},
  year = {2014},
  month = feb,
  abstract = {Long Short-Term Memory (LSTM) is a recurrent neural network (RNN) architecture that has been designed to address the vanishing and exploding gradient problems of conventional RNNs. Unlike feedforward neural networks, RNNs have cyclic connections making them powerful for modeling sequences. They have been successfully used for sequence labeling and sequence prediction tasks, such as handwriting recognition, language modeling, phonetic labeling of acoustic frames. However, in contrast to the deep neural networks, the use of RNNs in speech recognition has been limited to phone recognition in small scale tasks. In this paper, we present novel LSTM based RNN architectures which make more effective use of model parameters to train acoustic models for large vocabulary speech recognition. We train and compare LSTM, RNN and DNN models at various numbers of parameters and configurations. We show that LSTM models converge quickly and give state of the art speech recognition performance for relatively small sized models.},
  archiveprefix = {arXiv},
  eprint = {1402.1128},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\TNF97QWS\\Sak et al_2014_Long Short-Term Memory Based Recurrent Neural Network Architectures for Large.pdf;E\:\\Zotero\\storage\\ZRV62DUX\\1402.html},
  journal = {arXiv:1402.1128 [cs, stat]},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,math-thesis,math-thesis:dl,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@book{salvadorREINFORCEMENTLEARNINGLITERATURE2020,
  title = {{{REINFORCEMENT LEARNING}}: {{A LITERATURE REVIEW}} ({{September}} 2020)},
  shorttitle = {{{REINFORCEMENT LEARNING}}},
  author = {Salvador, Jos{\'e} and Oliveira, Jo{\~a}o and Breternitz, Maur{\'i}cio},
  year = {2020},
  month = oct,
  doi = {10.13140/RG.2.2.30323.76327},
  abstract = {This paper contains a literature review of Reinforcement Learning and its evolution. Reinforcement Learning is a part of Machine Learning and comprises algorithms and techniques to achieve optimal control of an Agent in an Environment providing a type of Artificial Intelligence. This Agent can be a physical or virtual robot, can be a controller simulating a player in a game, or a bot trading stocks, etc. The study starts at Q-learning [56] published in 1989 and follows the thread of algorithms and frameworks up until 2020, looking at main insights each paper brings to the field regarding strategies to handle RL.},
  file = {E\:\\Zotero\\storage\\F86QFST7\\Salvador et al_2020_REINFORCEMENT LEARNING.pdf},
  keywords = {math-thesis,math-thesis:review}
}

@inproceedings{santoroMetaLearningMemoryAugmentedNeural2016,
  title = {Meta-{{Learning}} with {{Memory}}-{{Augmented Neural Networks}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
  year = {2016},
  month = jun,
  pages = {1842--1850},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of},
  file = {E\:\\Zotero\\storage\\LIXWRMHV\\Santoro et al_2016_Meta-Learning with Memory-Augmented Neural Networks.pdf;E\:\\Zotero\\storage\\HRSIHYRK\\santoro16.html},
  keywords = {math-thesis},
  language = {en}
}

@article{schaulPrioritizedExperienceReplay2016,
  title = {Prioritized {{Experience Replay}}},
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  year = {2016},
  month = feb,
  abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new stateof-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
  archiveprefix = {arXiv},
  eprint = {1511.05952},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\M4GYQZ73\\Schaul et al_2016_Prioritized Experience Replay.pdf},
  journal = {arXiv:1511.05952 [cs]},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,ICLR,ICLR 2016,math-thesis},
  language = {en},
  primaryclass = {cs}
}

@inproceedings{schaulUniversalValueFunction2015,
  title = {Universal {{Value Function Approximators}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  year = {2015},
  month = jun,
  pages = {1312--1320},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, usi...},
  file = {E\:\\Zotero\\storage\\37Z7IBJH\\Schaul et al_2015_Universal Value Function Approximators.pdf;E\:\\Zotero\\storage\\5MTQLBQQ\\schaul15.html},
  keywords = {_to_do,math-thesis},
  language = {en}
}

@phdthesis{schmidhuberEvolutionaryPrinciplesSelfreferential1987,
  title = {Evolutionary Principles in Self-Referential Learning, or on Learning How to Learn: {{The}} Meta-Meta-... Hook},
  shorttitle = {Evolutionary Principles in Self-Referential Learning, or on Learning How to Learn},
  author = {Schmidhuber, J{\"u}rgen},
  year = {1987},
  file = {E\:\\Zotero\\storage\\FVAGI7CC\\813180.html},
  keywords = {math-thesis,math-thesis:meta-learning},
  school = {Technische Universit\"at M\"unchen}
}

@article{schulmanProximalPolicyOptimization2017,
  title = {Proximal {{Policy Optimization Algorithms}}},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  year = {2017},
  month = aug,
  abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
  archiveprefix = {arXiv},
  eprint = {1707.06347},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\C8I3333S\\Schulman et al_2017_Proximal Policy Optimization Algorithms.pdf;E\:\\Zotero\\storage\\ZQ64HB66\\1707.html},
  journal = {arXiv:1707.06347 [cs]},
  keywords = {Computer Science - Machine Learning,math-thesis},
  primaryclass = {cs}
}

@inproceedings{schulmanTrustRegionPolicy2015,
  title = {Trust Region Policy Optimization},
  booktitle = {International Conference on Machine Learning},
  author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  year = {2015},
  pages = {1889--1897},
  publisher = {{PMLR}},
  file = {E\:\\Zotero\\storage\\7QLPYNKP\\Schulman et al_2015_Trust region policy optimization.pdf;E\:\\Zotero\\storage\\9XS8VPPM\\schulman15.html},
  keywords = {math-thesis}
}

@inproceedings{shatnawiComparativeStudyOpen2018,
  title = {A Comparative Study of Open Source Deep Learning Frameworks},
  booktitle = {2018 9th {{International Conference}} on {{Information}} and {{Communication Systems}} ({{ICICS}})},
  author = {Shatnawi, A. and {Al-Bdour}, G. and {Al-Qurran}, R. and {Al-Ayyoub}, M.},
  year = {2018},
  month = apr,
  pages = {72--77},
  issn = {2573-3346},
  doi = {10/gf4wmw},
  abstract = {Deep Learning (DL) is one of the hottest trends in machine learning as DL approaches produced results superior to the state-of-the-art in problematic areas such as image processing and natural language processing (NLP). To foster the growth of the DL community, several open source frameworks appeared providing implementations of the most common DL algorithms. These frameworks vary in the algorithms they support and in the quality of their implementations. The purpose of this work is to provide a qualitative and quantitative comparison among three of the most popular and most comprehensive DL frameworks (namely Google's TensorFlow, University of Montreal's Theano, and Microsoft's CNTK). The ultimate goal of this work is to help end users make an informed decision about the best DL framework that suits their needs and resources. To ensure that our study is as comprehensive as possible, we conduct several experiments using multiple benchmark datasets and measure the performance of the frameworks' implementation of different DL algorithms. For most of our experiments, we find out that CNTK's implementations are superior to the other ones under consideration.},
  file = {E\:\\Zotero\\storage\\PFE836HP\\Shatnawi et al_2018_A comparative study of open source deep learning frameworks.pdf;E\:\\Zotero\\storage\\KUNIAQFR\\8355444.html;E\:\\Zotero\\storage\\WEWYGIG6\\8355444.html},
  keywords = {C++ languages,CIFAR-10,CNN,CNTK,CNTK implementations,Deep Learning,DL framework,Graphics processing units,image processing,learning (artificial intelligence),Libraries,machine learning,Machine learning,MNIST,natural language processing,open source deep learning frameworks,open source frameworks,Portable computers,Python,qualitative comparison,quantitative comparison,Servers,TensorFlow,Theano}
}

@misc{ShenDuQiangHuaXueXiFaZhanShi,
  title = {{深度强化学习发展史}},
  abstract = {如今机器学习发展如此迅猛，各类算法层出不群，特别是深度神经网络在计算机视觉、自然语言处理、时间序列预测等多个领域更是战果累累，可以说这波浪潮带动了很多人进入深度学习领域，也成就了其一番事业。而强化学\ldots},
  file = {E\:\\Zotero\\storage\\TIGB22XJ\\56399184.html},
  howpublished = {https://zhuanlan.zhihu.com/p/56399184},
  journal = {知乎专栏},
  keywords = {math-thesis},
  language = {zh}
}

@inproceedings{shvachkoHadoopDistributedFile2010,
  title = {The {{Hadoop Distributed File System}}},
  booktitle = {2010 {{IEEE}} 26th {{Symposium}} on {{Mass Storage Systems}} and {{Technologies}} ({{MSST}})},
  author = {Shvachko, Konstantin and Kuang, Hairong and Radia, Sanjay and Chansler, Robert},
  year = {2010},
  month = may,
  pages = {1--10},
  publisher = {{IEEE}},
  address = {{Incline Village, NV, USA}},
  doi = {10/d6cm8p},
  abstract = {The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of HDFS and report on experience using HDFS to manage 25 petabytes of enterprise data at Yahoo!.},
  file = {E\:\\Zotero\\storage\\5PQECTCT\\Shvachko et al. - 2010 - The Hadoop Distributed File System.pdf},
  isbn = {978-1-4244-7152-2},
  keywords = {Hadoop},
  language = {en}
}

@inproceedings{silverDeterministicPolicyGradient2014,
  ids = {silverDeterministicPolicyGradient},
  title = {Deterministic Policy Gradient Algorithms},
  author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year = {2014},
  file = {E\:\\Zotero\\storage\\IKN69TN2\\Silver et al_2014_Deterministic policy gradient algorithms.pdf},
  keywords = {⛔ No DOI found,math-thesis}
}

@article{silverMasteringGameGo2016,
  title = {Mastering the Game of {{Go}} with Deep Neural Networks and Tree Search},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and {van den Driessche}, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  year = {2016},
  month = jan,
  volume = {529},
  pages = {484--489},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10/f77tw6},
  abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks' to evaluate board positions and `policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
  copyright = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  file = {E\:\\Zotero\\storage\\NU2HCJQP\\Silver et al_2016_Mastering the game of Go with deep neural networks and tree search.pdf;E\:\\Zotero\\storage\\H2AYR6AY\\nature16961.html},
  journal = {Nature},
  keywords = {math-thesis},
  language = {en},
  number = {7587}
}

@article{silverMasteringGameGo2017,
  title = {Mastering the Game of {{Go}} without Human Knowledge},
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and {van den Driessche}, George and Graepel, Thore and Hassabis, Demis},
  year = {2017},
  month = oct,
  volume = {550},
  pages = {354--359},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10/gcsmk9},
  abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100\textendash 0 against the previously published, champion-defeating AlphaGo.},
  copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
  file = {E\:\\Zotero\\storage\\WCIWANNF\\Silver et al_2017_Mastering the game of Go without human knowledge.pdf;E\:\\Zotero\\storage\\TRAHUSTC\\nature24270.html},
  journal = {Nature},
  language = {en},
  number = {7676}
}

@book{situolinsiCaoZuoXiTongJingSuiYuSheJiYuanLiOperating2017,
  title = {{操作系统: 精髓与设计原理 = Operating systems}},
  shorttitle = {{操作系统}},
  author = {{斯托林斯} and {陈向群}},
  year = {2017},
  publisher = {{电子工业出版社}},
  address = {{北京}},
  abstract = {Ben shu ji shi guan yu cao zuo xi tong gai nian,Jie gou he ji zhi de jiao cai,Mu de shi jin ke neng qing chu he quan mian di zhan shi xian dai cao zuo xi tong de ben zhi he te dian:ye shi jiang jie cao zuo xi tong de jing dian jiao cai,Bu jin xi tong di jiang shu le cao zuo xi tong de ji ben gai nian,Yuan li he fang fa,Er qie yi dang dai zui liu xing de cao zuo xi tong Windows 8,UNIX,Android,Linux wei li,Zhan xian le dang dai cao zuo xi tong de ben zhi he te dian.},
  annotation = {OCLC: 1052482133},
  file = {E\:\\Zotero\\storage\\MHC66XIS\\斯托林斯_陈向群_2017_操作系统.pdf},
  isbn = {978-7-121-30950-2},
  language = {Chinese}
}

@inproceedings{smithCyclicalLearningRates2017,
  title = {Cyclical {{Learning Rates}} for {{Training Neural Networks}}},
  booktitle = {2017 {{IEEE Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Smith, Leslie N.},
  year = {2017},
  month = mar,
  pages = {464--472},
  publisher = {{IEEE}},
  address = {{Santa Rosa, CA, USA}},
  doi = {10/gfpb29},
  abstract = {It is known that the learning rate is the most important hyper-parameter to tune for training deep neural networks. This paper describes a new method for setting the learning rate, named cyclical learning rates, which practically eliminates the need to experimentally find the best values and schedule for the global learning rates. Instead of monotonically decreasing the learning rate, this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations. This paper also describes a simple way to estimate ``reasonable bounds'' \textendash{} linearly increasing the learning rate of the network for a few epochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10 and CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets, and the ImageNet dataset with the AlexNet and GoogLeNet architectures. These are practical tools for everyone who trains neural networks.},
  file = {E\:\\Zotero\\storage\\A2EAQCGX\\Smith_2017_Cyclical Learning Rates for Training Neural Networks.pdf},
  isbn = {978-1-5090-4822-9},
  language = {en}
}

@book{steinComplexAnalysis2003,
  title = {Complex Analysis},
  author = {Stein, Elias M. and Shakarchi, Rami},
  year = {2003},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J}},
  annotation = {OCLC: ocm51738532},
  file = {E\:\\Zotero\\storage\\D25TA3VL\\Stein_Shakarchi_2003_Complex analysis.pdf},
  isbn = {978-0-691-11385-2},
  language = {en},
  lccn = {QA331 .S743 2003},
  number = {2},
  series = {Princeton Lectures in Analysis}
}

@book{steinFourierAnalysisIntroduction2003,
  title = {Fourier Analysis: An Introduction},
  shorttitle = {Fourier Analysis},
  author = {Stein, Elias M. and Shakarchi, Rami},
  year = {2003},
  publisher = {{Princeton University Press}},
  address = {{Princeton}},
  file = {E\:\\Zotero\\storage\\C5LDKIAZ\\Stein_Shakarchi_2003_Fourier analysis.pdf},
  isbn = {978-0-691-11384-5},
  language = {en},
  lccn = {QA403.5 .S74 2003},
  number = {1},
  series = {Princeton Lectures in Analysis}
}

@book{steinRealAnalysisMeasure2005,
  title = {Real Analysis: Measure Theory, Integration, and {{Hilbert}} Spaces},
  shorttitle = {Real Analysis},
  author = {Stein, Elias M. and Shakarchi, Rami},
  year = {2005},
  publisher = {{Princeton University Press}},
  address = {{Princeton, N.J}},
  file = {E\:\\Zotero\\storage\\2Q9A87KC\\Stein_Shakarchi_2005_Real analysis.pdf},
  isbn = {978-0-691-11386-9},
  language = {en},
  lccn = {QA320 .S84 2005},
  number = {v. 3},
  series = {Princeton Lectures in Analysis}
}

@book{sunOptimizationTheoryMethods2006,
  title = {Optimization Theory and Methods: Nonlinear Programming},
  shorttitle = {Optimization Theory and Methods},
  author = {Sun, Wenyu and Yuan, Ya-xiang},
  year = {2006},
  publisher = {{Springer}},
  address = {{New York}},
  annotation = {OCLC: ocm60311926},
  file = {E\:\\Zotero\\storage\\F7MH9W8G\\Sun and Yuan - 2006 - Optimization theory and methods nonlinear program.pdf;E\:\\Zotero\\storage\\G3GTD5T9\\最优化理论与方法(袁亚湘 孙文瑜).pdf},
  isbn = {978-0-387-24975-9},
  keywords = {Mathematical optimization,Nonlinear programming},
  lccn = {T57.8 .S86 2006},
  number = {v. 1},
  series = {Springer Optimization and Its Applications}
}

@inproceedings{suttonAdaptingBiasGradient1992,
  title = {Adapting Bias by Gradient Descent: {{An}} Incremental Version of Delta-Bar-Delta},
  shorttitle = {Adapting Bias by Gradient Descent},
  booktitle = {{{AAAI}}},
  author = {Sutton, Richard S.},
  year = {1992},
  pages = {171--176},
  publisher = {{San Jose, CA}},
  file = {E\:\\Zotero\\storage\\NG7FG5TA\\Sutton_1992_Adapting bias by gradient descent.pdf},
  keywords = {⛔ No DOI found,math-thesis}
}

@inproceedings{suttonHordeScalableRealtime2011,
  title = {Horde: {{A}} Scalable Real-Time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction},
  shorttitle = {Horde},
  booktitle = {The 10th {{International Conference}} on {{Autonomous Agents}} and {{Multiagent Systems}}-{{Volume}} 2},
  author = {Sutton, Richard S. and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M. and White, Adam and Precup, Doina},
  year = {2011},
  pages = {761--768},
  file = {E\:\\Zotero\\storage\\JHZLA6F8\\Sutton et al_2011_Horde.pdf},
  keywords = {math-thesis}
}

@article{suttonLearningPredictMethods1988,
  title = {Learning to Predict by the Methods of Temporal Differences},
  author = {Sutton, Richard S.},
  year = {1988},
  volume = {3},
  pages = {9--44},
  publisher = {{Springer}},
  file = {E\:\\Zotero\\storage\\MQMXXIAJ\\Sutton_1988_Learning to predict by the methods of temporal differences.pdf},
  journal = {Machine learning},
  keywords = {math-thesis},
  number = {1}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  file = {E\:\\Zotero\\storage\\BTPJ5XXI\\Sutton and Barto - 2018 - Reinforcement learning an introduction.pdf;E\:\\Zotero\\storage\\PHPU6SW9\\the-book.html;E\:\\Zotero\\storage\\XXZKFQIS\\errata.html},
  isbn = {978-0-262-03924-6},
  keywords = {_have_read,math-thesis,math-thesis:book,Reinforcement learning},
  language = {en},
  lccn = {Q325.6 .R45 2018},
  series = {Adaptive Computation and Machine Learning Series}
}

@book{tanenbaomuXianDaiCaoZuoXiTongModernOperating2017,
  title = {{现代操作系统 = Modern operating systems}},
  author = {{塔嫩鲍姆} and {博斯} and {陈向群} and {马洪兵}},
  year = {2017},
  publisher = {{机械工业出版社}},
  address = {{北京}},
  abstract = {Ben shu zhu yao nei rong bao kuo jin cheng yu xian cheng,Nei cun guan li,Wen jian xi tong,Shu ru/ shu chu,Si suo,Xu ni hua he yun,Duo chu li ji xi tong,An quan,Yi ji guan yu UNIX,Linux,Android he Windows de shi li yan jiu deng.},
  annotation = {OCLC: 1050890978},
  file = {E\:\\Zotero\\storage\\8M96HKN8\\塔嫩鲍姆 et al_2017_现代操作系统 = Modern operating systems.pdf},
  isbn = {978-7-111-57369-2},
  language = {Chinese}
}

@article{tang1bitAdamCommunication2021,
  title = {1-Bit {{Adam}}: {{Communication Efficient Large}}-{{Scale Training}} with {{Adam}}'s {{Convergence Speed}}},
  shorttitle = {1-Bit {{Adam}}},
  author = {Tang, Hanlin and Gan, Shaoduo and Awan, Ammar Ahmad and Rajbhandari, Samyam and Li, Conglong and Lian, Xiangru and Liu, Ji and Zhang, Ce and He, Yuxiong},
  year = {2021},
  month = feb,
  abstract = {Scalable training of large models (like BERT and GPT-3) requires careful optimization rooted in model design, architecture, and system capabilities. From a system standpoint, communication has become a major bottleneck, especially on commodity systems with standard TCP interconnects that offer limited network bandwidth. Communication compression is an important technique to reduce training time on such systems. One of the most effective methods is error-compensated compression, which offers robust convergence speed even under 1-bit compression. However, state-of-the-art error compensation techniques only work with basic optimizers like SGD and momentum SGD, which are linearly dependent on the gradients. They do not work with non-linear gradient-based optimizers like Adam, which offer state-of-the-art convergence efficiency and accuracy for models like BERT. In this paper, we propose 1-bit Adam that reduces the communication volume by up to \$5\textbackslash times\$, offers much better scalability, and provides the same convergence speed as uncompressed Adam. Our key finding is that Adam's variance (non-linear term) becomes stable (after a warmup phase) and can be used as a fixed precondition for the rest of the training (compression phase). Experiments on up to 256 GPUs show that 1-bit Adam enables up to \$3.3\textbackslash times\$ higher throughput for BERT-Large pre-training and up to \$2.9\textbackslash times\$ higher throughput for SQuAD fine-tuning. In addition, we provide theoretical analysis for our proposed work.},
  archiveprefix = {arXiv},
  eprint = {2102.02888},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\PT9MXUDR\\Tang et al_2021_1-bit Adam.pdf;E\:\\Zotero\\storage\\5EZNS3TD\\2102.html},
  journal = {arXiv:2102.02888 [cs]},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,DeepSpeed},
  primaryclass = {cs}
}

@techreport{thrunLearningOneMore1994,
  title = {Learning One More Thing},
  author = {Thrun, Sebastian and Mitchell, Tom M.},
  year = {1994},
  institution = {{CARNEGIE-MELLON UNIV PITTSBURGH PA DEPT OF COMPUTER SCIENCE}},
  file = {E\:\\Zotero\\storage\\T35TGS4E\\Thrun_Mitchell_1994_Learning one more thing.pdf;E\:\\Zotero\\storage\\64WX6ASY\\ADA285342.html},
  keywords = {math-thesis}
}

@inproceedings{tokuiChainerNextgenerationOpen2015,
  title = {Chainer: A next-Generation Open Source Framework for Deep Learning},
  shorttitle = {Chainer},
  booktitle = {Proceedings of Workshop on Machine Learning Systems ({{LearningSys}}) in the Twenty-Ninth Annual Conference on Neural Information Processing Systems ({{NIPS}})},
  author = {Tokui, Seiya and Oono, Kenta and Hido, Shohei and Clayton, Justin},
  year = {2015},
  volume = {5},
  pages = {1--6},
  file = {E\:\\Zotero\\storage\\J8JS3MT4\\Tokui et al_2015_Chainer.pdf}
}

@inproceedings{vanhasseltDeepReinforcementLearning2016,
  ids = {vanhasseltDeepReinforcementLearning2015},
  title = {Deep Reinforcement Learning with Double Q-Learning},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
  year = {2016},
  volume = {30},
  archiveprefix = {arXiv},
  eprint = {1509.06461},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\C34A6L6L\\Van Hasselt et al_2016_Deep reinforcement learning with double q-learning.pdf;E\:\\Zotero\\storage\\GC59Q8N3\\10295.html},
  keywords = {AAAI,AAAI 2016,Computer Science - Machine Learning,math-thesis}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\textbackslash}Lukasz and Polosukhin, Illia},
  year = {2017},
  pages = {5998--6008},
  archiveprefix = {arXiv},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\P2CMCUAA\\Vaswani et al_2017_Attention is all you need.pdf;E\:\\Zotero\\storage\\Q26AS8DR\\Vaswani et al_2017_Attention Is All You Need.pdf;E\:\\Zotero\\storage\\A9IHIVMU\\3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  keywords = {_no_read,⛔ No DOI found,Computer Science - Computation and Language,Computer Science - Machine Learning,NeurIPS}
}

@inproceedings{vavilapalliApacheHadoopYARN2013,
  title = {Apache {{Hadoop YARN}}: Yet Another Resource Negotiator},
  shorttitle = {Apache {{Hadoop YARN}}},
  booktitle = {Proceedings of the 4th Annual {{Symposium}} on {{Cloud Computing}}},
  author = {Vavilapalli, Vinod Kumar and Murthy, Arun C. and Douglas, Chris and Agarwal, Sharad and Konar, Mahadev and Evans, Robert and Graves, Thomas and Lowe, Jason and Shah, Hitesh and Seth, Siddharth and Saha, Bikas and Curino, Carlo and O'Malley, Owen and Radia, Sanjay and Reed, Benjamin and Baldeschwieler, Eric},
  year = {2013},
  month = oct,
  pages = {1--16},
  publisher = {{ACM}},
  address = {{Santa Clara California}},
  doi = {10/gg4wjc},
  abstract = {The initial design of Apache Hadoop [1] was tightly focused on running massive, MapReduce jobs to process a web crawl. For increasingly diverse companies, Hadoop has become the data and computational agora\textasciiacute{} \textemdash the de facto place where data and computational resources are shared and accessed. This broad adoption and ubiquitous usage has stretched the initial design well beyond its intended target, exposing two key shortcomings: 1) tight coupling of a specific programming model with the resource management infrastructure, forcing developers to abuse the MapReduce programming model, and 2) centralized handling of jobs' control flow, which resulted in endless scalability concerns for the scheduler.},
  file = {E\:\\Zotero\\storage\\QGYI8DVE\\Vavilapalli et al. - 2013 - Apache Hadoop YARN yet another resource negotiato.pdf},
  isbn = {978-1-4503-2428-1},
  keywords = {Hadoop},
  language = {en}
}

@inproceedings{vinyalsMatchingNetworksOne2016b,
  title = {Matching Networks for One Shot Learning},
  booktitle = {Proceedings of the 30th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Kavukcuoglu, Koray and Wierstra, Daan},
  year = {2016},
  month = dec,
  pages = {3637--3645},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6\% to 93.2\% and from 88.0\% to 93.8\% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
  file = {E\:\\Zotero\\storage\\S7FHUEZR\\Vinyals et al_2016_Matching networks for one shot learning.pdf},
  isbn = {978-1-5108-3881-9},
  keywords = {math-thesis},
  series = {{{NIPS}}'16}
}

@inproceedings{wangDuelingNetworkArchitectures2016,
  title = {Dueling {{Network Architectures}} for {{Deep Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  year = {2016},
  month = jun,
  pages = {1995--2003},
  publisher = {{PMLR}},
  issn = {1938-7228},
  abstract = {In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional netwo...},
  file = {E\:\\Zotero\\storage\\KPMGVE35\\Wang et al_2016_Dueling Network Architectures for Deep Reinforcement Learning.pdf;E\:\\Zotero\\storage\\MP8FNBB7\\wangf16.html;E\:\\Zotero\\storage\\PD366TKE\\wangf16.html},
  keywords = {ICML,ICML 2016},
  language = {en}
}

@article{wangIMPROVINGMMDGANTRAINING2019,
  title = {{{IMPROVING MMD}}-{{GAN TRAINING WITH REPULSIVE LOSS FUNCTION}}},
  author = {Wang, Wei and Sun, Yuan and Halgamuge, Saman},
  year = {2019},
  pages = {24},
  file = {E\:\\Zotero\\storage\\WIARDUVC\\Wang et al. - 2019 - IMPROVING MMD-GAN TRAINING WITH REPULSIVE LOSS FUN.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{wangWeakSupervisionFake2020,
  title = {Weak {{Supervision}} for {{Fake News Detection}} via {{Reinforcement Learning}}},
  author = {Wang, Yaqing and Yang, Weifeng and Ma, Fenglong and Xu, Jin and Zhong, Bin and Deng, Qiang and Gao, Jing},
  year = {2020},
  month = apr,
  volume = {34},
  pages = {516--523},
  issn = {2374-3468},
  doi = {10/ghtvw5},
  copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
  file = {E\:\\Zotero\\storage\\4RT23PW2\\Wang et al_2020_Weak Supervision for Fake News Detection via Reinforcement Learning.pdf;E\:\\Zotero\\storage\\UIL442JA\\5389.html},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  keywords = {AAAI,AAAI 2020},
  language = {en},
  number = {01}
}

@book{wangyanjunZuiYouHuaJiChuLiLunYuFangFa2011,
  title = {{最优化基础理论与方法}},
  author = {{王燕军}},
  year = {2011},
  publisher = {{复旦大学出版社}},
  address = {{上海}},
  file = {E\:\\Zotero\\storage\\A5YNNT3H\\最优化基础理论与方法.pdf},
  isbn = {978-7-309-13987-7},
  language = {Chinese}
}

@inproceedings{watanabeProgramGenerationML2017,
  title = {Program Generation for {{ML}} Modules (Short Paper)},
  booktitle = {Proceedings of the {{ACM SIGPLAN Workshop}} on {{Partial Evaluation}} and {{Program Manipulation}}},
  author = {Watanabe, Takahisa and Kameyama, Yukiyoshi},
  year = {2017},
  month = dec,
  pages = {60--66},
  publisher = {{ACM}},
  address = {{Los Angeles CA USA}},
  doi = {10/ghrq2h},
  abstract = {Program generation has been successful in various domains which need high performance and high productivity. Yet, programming-language supports for program generation need further improvement. An important omission is the functionality of generating modules in a type safe way. Inoue et al. have addressed this issue in 2016, but investigated only a few examples. We propose a language as an extension of (a small subset of) MetaOCaml in which one can manipulate and generate code of a module, and implement it based on a simple translation to MetaOCaml. We show that our language solves the performance problem in functor applications pointed out by Inoue et al., and that it provides a suitable basis for writing code generators for modules.},
  file = {E\:\\Zotero\\storage\\ZZU6YVQM\\Watanabe and Kameyama - 2017 - Program generation for ML modules (short paper).pdf},
  isbn = {978-1-4503-5587-2},
  language = {en}
}

@article{watkinsQlearning1992,
  title = {Q-Learning},
  author = {Watkins, Christopher JCH and Dayan, Peter},
  year = {1992},
  volume = {8},
  pages = {279--292},
  publisher = {{Springer}},
  file = {E\:\\Zotero\\storage\\55PULN4A\\Watkins_Dayan_1992_Q-learning.pdf},
  journal = {Machine learning},
  keywords = {math-thesis,math-thesis:classic},
  number = {3-4}
}

@book{wenzaiwenZuiYouHuaJianMoSuanFaYuLiLun2020,
  title = {最优化：建模、算法与理论},
  author = {{文再文}},
  year = {2020},
  file = {E\:\\Zotero\\storage\\E78RF4CL\\最优化建模.pdf}
}

@inproceedings{wiskundeDoubleQlearningHadoVan2010,
  title = {{{DoubleQ}}-Learning {{Hado}} van {{Hasselt Multi}}-Agent and {{Adaptive Computation Group}}},
  booktitle = {{{NIPS}}},
  author = {Wiskunde, Centrum},
  year = {2010},
  abstract = {In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. We apply the double estimator to Q-learning to construct Double Q-learning, a new off-policy reinforcement learning algorithm. We show the new algorithm converges to the optimalpolicyandthatitperformswellinsomesettingsinwhichQ-learningperformspoorly due toitsoverestimation. 1},
  file = {E\:\\Zotero\\storage\\MEYQ9I2V\\Wiskunde_DoubleQ-learning Hado van Hasselt Multi-agent and Adaptive Computation Group.pdf;E\:\\Zotero\\storage\\SA26QSAP\\summary.html}
}

@book{xiangliangTuiJianXiTongShiJian2012,
  title = {{推荐系统实践}},
  author = {{项亮}},
  year = {2012},
  annotation = {OCLC: 1104191920},
  file = {E\:\\Zotero\\storage\\LRNYDRH3\\项亮_2012_推荐系统实践.pdf},
  isbn = {978-7-115-28158-6},
  language = {Chinese}
}

@article{xuDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} with {{Stacked Hierarchical Attention}} for {{Text}}-Based {{Games}}},
  author = {Xu, Yunqiu and Fang, Meng and Chen, Ling and Du, Yali and Zhou, Joey Tianyi and Zhang, Chengqi},
  year = {2020},
  volume = {33},
  file = {E\:\\Zotero\\storage\\KUWL4JUY\\Xu et al_2020_Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based.pdf;E\:\\Zotero\\storage\\FPIUFGYQ\\bf65417dcecc7f2b0006e1f5793b7143-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {_to_do,⛔ No DOI found,math-thesis,NeurIPS,NeurIPS 2020},
  language = {en}
}

@inproceedings{xuMetagradientReinforcementLearning2018,
  title = {Meta-Gradient Reinforcement Learning},
  booktitle = {Proceedings of the 32nd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Xu, Zhongwen and {van Hasselt}, Hado and Silver, David},
  year = {2018},
  month = dec,
  pages = {2402--2413},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  abstract = {The goal of reinforcement learning algorithms is to estimate and/or optimise the value function. However, unlike supervised learning, no teacher or oracle is available to provide the true value function. Instead, the majority of reinforcement learning algorithms estimate and/or optimise a proxy for the value function. This proxy is typically based on a sampled and bootstrapped approximation to the true value function, known as a return. The particular choice of return is one of the chief components determining the nature of the algorithm: the rate at which future rewards are discounted; when and how values should be bootstrapped; or even the nature of the rewards themselves. It is well-known that these decisions are crucial to the overall success of RL algorithms. We discuss a gradient-based meta-learning algorithm that is able to adapt the nature of the return, online, whilst interacting and learning from the environment. When applied to 57 games on the Atari 2600 environment over 200 million frames, our algorithm achieved a new state-of-the-art performance.},
  file = {E\:\\Zotero\\storage\\BCV3X7LE\\Xu et al_2018_Meta-gradient reinforcement learning.pdf},
  keywords = {math-thesis},
  series = {{{NIPS}}'18}
}

@inproceedings{yangEmpiricalGuideBehavior2020a,
  title = {An Empirical Guide to the Behavior and Use of Scalable Persistent Memory},
  booktitle = {18th \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Conference}} on {{File}} and {{Storage Technologies}} (\$\{\$\vphantom\}{{FAST}}\$\vphantom\{\}\$ 20)},
  author = {Yang, Jian and Kim, Juno and Hoseinzadeh, Morteza and Izraelevitz, Joseph and Swanson, Steve},
  year = {2020},
  pages = {169--182},
  file = {E\:\\Zotero\\storage\\C3LKDK35\\Yang et al_2020_An empirical guide to the behavior and use of scalable persistent memory.pdf;E\:\\Zotero\\storage\\5E5U8G8N\\yang.html}
}

@article{yePlayingFullMOBA2020,
  title = {Towards {{Playing Full MOBA Games}} with {{Deep Reinforcement Learning}}},
  author = {Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and Yin, Yinyuting and Shi, Bei and Wang, Liang and Shi, Tengfei and Fu, Qiang and Yang, Wei and Huang, Lanxiao and Liu, Wei},
  year = {2020},
  volume = {33},
  file = {E\:\\Zotero\\storage\\2CYN82T3\\Ye et al_2020_Towards Playing Full MOBA Games with Deep Reinforcement Learning.pdf;E\:\\Zotero\\storage\\W3E86UD8\\Ye et al_2020_Towards Playing Full MOBA Games with Deep Reinforcement Learning.pdf;E\:\\Zotero\\storage\\5359RFPQ\\06d5ae105ea1bea4d800bc96491876e9-Abstract.html;E\:\\Zotero\\storage\\DCFDRYJ7\\06d5ae105ea1bea4d800bc96491876e9-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  keywords = {NeurIPS,NeurIPS 2020},
  language = {en}
}

@article{yosinskiHowTransferableAre,
  title = {How Transferable Are Features in Deep Neural Networks?},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  file = {E\:\\Zotero\\storage\\4H83RGR7\\Yosinski et al_How transferable are features in deep neural networks.pdf}
}

@book{zahariaArchitectureFastGeneral2016,
  title = {An {{Architecture}} for {{Fast}} and {{General Data Processing}} on {{Large Clusters}}},
  author = {Zaharia, Matei},
  year = {2016},
  month = apr,
  publisher = {{Association for Computing Machinery}},
  doi = {10.1145/2886107},
  file = {E\:\\Zotero\\storage\\NPXY2BHZ\\Zaharia - 2016 - An Architecture for Fast and General Data Processi.pdf},
  isbn = {978-1-970001-57-0},
  language = {en}
}

@article{zahariaResilientDistributedDatasets2012,
  title = {Resilient {{Distributed Datasets}}: {{A Fault}}-{{Tolerant Abstraction}} for {{In}}-{{Memory Cluster Computing}}},
  author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur and Ma, Justin and McCauley, Murphy and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
  year = {2012},
  pages = {14},
  abstract = {We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarsegrained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.},
  file = {E\:\\Zotero\\storage\\BYQ9HIGK\\Zaharia et al_Resilient Distributed Datasets.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{zahariaSparkClusterComputing2010,
  title = {Spark: {{Cluster Computing}} with {{Working Sets}}},
  author = {Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J and Shenker, Scott and Stoica, Ion},
  year = {2010},
  pages = {7},
  abstract = {MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.},
  file = {E\:\\Zotero\\storage\\SXU2VNZJ\\Zaharia et al_Spark.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{zarembaRecurrentNeuralNetwork2015,
  title = {Recurrent {{Neural Network Regularization}}},
  author = {Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
  year = {2015},
  month = feb,
  abstract = {We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation.},
  archiveprefix = {arXiv},
  eprint = {1409.2329},
  eprinttype = {arxiv},
  file = {E\:\\Zotero\\storage\\MCE2S868\\Zaremba et al_2015_Recurrent Neural Network Regularization.pdf;E\:\\Zotero\\storage\\8MHUJVH8\\1409.html},
  journal = {arXiv:1409.2329 [cs]},
  keywords = {Computer Science - Neural and Evolutionary Computing,math-thesis},
  primaryclass = {cs}
}

@article{zhangAcceleratingTrainingTransformerBased2020,
  title = {Accelerating {{Training}} of {{Transformer}}-{{Based Language Models}} with {{Progressive Layer Dropping}}},
  author = {Zhang, Minjia and He, Yuxiong},
  year = {2020},
  volume = {33},
  pages = {14011--14023},
  file = {E\:\\Zotero\\storage\\BG4XLRED\\Zhang_He_2020_Accelerating Training of Transformer-Based Language Models with Progressive.pdf;E\:\\Zotero\\storage\\TR5QLNLD\\a1140a3d0df1c81e24ae954d935e8926-Abstract.html},
  journal = {Advances in Neural Information Processing Systems},
  language = {en}
}

@inproceedings{zhangEfficientCommunicationMultiagent2019,
  ids = {zhangEfficientCommunicationMultiAgent},
  title = {Efficient Communication in Multi-Agent Reinforcement Learning via Variance Based Control},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Zhang, Sai Qian and Zhang, Qi and Lin, Jieyu},
  year = {2019},
  pages = {3235--3244},
  file = {E\:\\Zotero\\storage\\4ZMIADRK\\Zhang et al. - Efficient Communication in Multi-Agent Reinforceme.pdf;E\:\\Zotero\\storage\\TDF5UL37\\Zhang et al_2019_Efficient communication in multi-agent reinforcement learning via variance.pdf;E\:\\Zotero\\storage\\92RZEBCR\\14cfdb59b5bda1fc245aadae15b1984a-Abstract.html}
}

@book{zhanggongqingBianFenXueJiangYi2011,
  title = {{变分学讲义}},
  author = {{张恭庆}},
  year = {2011},
  publisher = {{高等教育出版社}},
  address = {{北京}},
  abstract = {Ben shu shi zuo zhe zai bei jing da xue wei gao nian ji ben ke sheng he di nian ji yan jiu sheng kai she"bian fen xue"ke cheng suo yong de jiang yi. Quan shu gong er shi jiang, Fen wei san da bu fen:di yi bu fen shi jing dian bian fen xue de ji ben nei rong, Di er bu fen zhong dian jie shao zhi jie fang fa ji qi li lun ji chu, Di san bu fen shi zhuan ti xuan jiang.},
  annotation = {OCLC: 886230081},
  file = {E\:\\Zotero\\storage\\TY92RT55\\张恭庆_2011_变分学讲义.pdf},
  isbn = {978-7-04-031958-3},
  language = {Chinese}
}

@article{zhangLookaheadOptimizerSteps2019,
  title = {Lookahead {{Optimizer}}: K Steps Forward, 1 Step Back},
  author = {Zhang, Michael R and Lucas, James and Hinton, Geoffrey},
  year = {2019},
  pages = {19},
  abstract = {The vast majority of successful deep neural networks are trained using variants of stochastic gradient descent (SGD) algorithms. Recent attempts to improve SGD can be broadly categorized into two approaches: (1) adaptive learning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes, such as heavy-ball and Nesterov momentum. In this paper, we propose a new optimization algorithm, Lookahead, that is orthogonal to these previous approaches and iteratively updates two sets of weights. Intuitively, the algorithm chooses a search direction by looking ahead at the sequence of ``fast weights" generated by another optimizer. We show that Lookahead improves the learning stability and lowers the variance of its inner optimizer with negligible computation and memory cost. We empirically demonstrate Lookahead can significantly improve the performance of SGD and Adam, even with their default hyperparameter settings on ImageNet, CIFAR10/100, neural machine translation, and Penn Treebank.},
  file = {E\:\\Zotero\\storage\\XAU53DZ4\\Zhang et al_Lookahead Optimizer.pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@inproceedings{zhangRetiariiDeepLearning2020,
  title = {Retiarii: {{A Deep Learning Exploratory}}-{{Training Framework}}},
  shorttitle = {Retiarii},
  booktitle = {14th \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\$\{\$\vphantom\}{{OSDI}}\$\vphantom\{\}\$ 20)},
  author = {Zhang, Quanlu and Han, Zhenhua and Yang, Fan and Zhang, Yuge and Liu, Zhe and Yang, Mao and Zhou, Lidong},
  year = {2020},
  pages = {919--936},
  file = {E\:\\Zotero\\storage\\NV4U26BK\\Slides_Zhang et al_2020_Retiarii.pdf;E\:\\Zotero\\storage\\WNY4GL4I\\Zhang et al_2020_Retiarii.pdf;E\:\\Zotero\\storage\\ZVJBT7CN\\zhang-quanlu.html},
  keywords = {_have_read}
}

@misc{zhangZhangqianhuiAdversarialNetsPapers2021,
  title = {Zhangqianhui/{{AdversarialNetsPapers}}},
  author = {Zhang, Jichao},
  year = {2021},
  month = jan,
  abstract = {Awesome paper list with code about generative adversarial nets},
  keywords = {adversarial-networks,deep-learning,gan,image-translation}
}

@inproceedings{zhaoHiveDSharingGPU2020,
  title = {{{HiveD}}: {{Sharing}} a \$\{\$\vphantom\}{{GPU}}\$\vphantom\{\}\$ {{Cluster}} for {{Deep Learning}} with {{Guarantees}}},
  shorttitle = {{{HiveD}}},
  booktitle = {14th \$\{\$\vphantom\}{{USENIX}}\$\vphantom\{\}\$ {{Symposium}} on {{Operating Systems Design}} and {{Implementation}} (\$\{\$\vphantom\}{{OSDI}}\$\vphantom\{\}\$ 20)},
  author = {Zhao, Hanyu and Han, Zhenhua and Yang, Zhi and Zhang, Quanlu and Yang, Fan and Zhou, Lidong and Yang, Mao and Lau, Francis CM and Wang, Yuqi and Xiong, Yifan},
  year = {2020},
  pages = {515--532},
  file = {E\:\\Zotero\\storage\\4FDHC9LJ\\Zhao et al_2020_HiveD.pdf;E\:\\Zotero\\storage\\FK4QRHF8\\Zhao et al_HiveD.pdf;E\:\\Zotero\\storage\\KRSHIZKB\\Zhao et al. - HiveD Sharing a GPU Cluster for Deep Learning wit.pdf;E\:\\Zotero\\storage\\VPFZQJH3\\zhao-hanyu.html},
  keywords = {_to_read,⛔ No DOI found}
}

@inproceedings{zhengHighPerformancePaged2016,
  title = {Towards High Performance Paged Memory for {{GPUs}}},
  booktitle = {2016 {{IEEE International Symposium}} on {{High Performance Computer Architecture}} ({{HPCA}})},
  author = {Zheng, Tianhao and Nellans, David and Zulfiqar, Arslan and Stephenson, Mark and Keckler, Stephen W.},
  year = {2016},
  month = mar,
  pages = {345--357},
  publisher = {{IEEE}},
  address = {{Barcelona, Spain}},
  doi = {10/gf6v87},
  abstract = {Despite industrial investment in both on-die GPUs and next generation interconnects, the highest performing parallel accelerators shipping today continue to be discrete GPUs. Connected via PCIe, these GPUs utilize their own privately managed physical memory that is optimized for high bandwidth. These separate memories force GPU programmers to manage the movement of data between the CPU and GPU, in addition to the on-chip GPU memory hierarchy. To simplify this process, GPU vendors are developing software runtimes that automatically page memory in and out of the GPU on-demand, reducing programmer effort and enabling computation across datasets that exceed the GPU memory capacity. Because this memory migration occurs over a high latency and low bandwidth link (compared to GPU memory), these software runtimes may result in significant performance penalties. In this work, we explore the features needed in GPU hardware and software to close the performance gap of GPU paged memory versus legacy programmer directed memory management. Without modifying the GPU execution pipeline, we show it is possible to largely hide the performance overheads of GPU paged memory, converting an average 2\texttimes{} slowdown into a 12\% speedup when compared to programmer directed transfers. Additionally, we examine the performance impact that GPU memory oversubscription has on application run times, enabling application designers to make informed decisions on how to shard their datasets across hosts and GPU instances.},
  file = {E\:\\Zotero\\storage\\UZZY48UJ\\Zheng et al. - 2016 - Towards high performance paged memory for GPUs.pdf},
  isbn = {978-1-4673-9211-2},
  language = {en}
}

@article{zhongSimultaneousConfidenceBands2020,
  title = {Simultaneous Confidence Bands for Comparing Variance Functions of Two Samples Based on Deterministic Designs},
  author = {Zhong, Chen and Yang, Lijian},
  year = {2020},
  month = oct,
  issn = {1613-9658},
  doi = {10/ghv5kj},
  abstract = {Asymptotically correct simultaneous confidence bands (SCBs) are proposed in both multiplicative and additive form to compare variance functions of two samples in the nonparametric regression model based on deterministic designs. The multiplicative SCB is based on two-step estimation of ratio of the variance functions, which is as efficient, up to order \$\$n\^\{-1/2\}\$\$n-1/2, as an infeasible estimator if the two mean functions are known a priori. The additive SCB, which is the log transform of the multiplicative SCB, is location and scale invariant in the sense that the width of SCB is free of the unknown mean and variance functions of both samples. Simulation experiments provide strong evidence that corroborates the asymptotic theory. The proposed SCBs are used to analyze several strata pressure data sets from the Bullianta Coal Mine in Erdos City, Inner Mongolia, China.},
  file = {E\:\\Zotero\\storage\\3X6D3VUN\\Zhong_Yang_2020_Simultaneous confidence bands for comparing variance functions of two samples.pdf},
  journal = {Computational Statistics},
  language = {en}
}

@book{zhouzhihuaJiQiXueXiMachineLearning2016,
  title = {{机器学习 = Machine learning}},
  author = {{周志華}},
  year = {2016},
  publisher = {{清华大学出版社}},
  address = {{北京}},
  abstract = {Ben shu gong 16 zhang, Fen wei 3 ge bu fen:di 1 bu fen(di 1-3 zhang)Jie shao ji qi xue xi de ji chu zhi shi;Di 2 bu fen(di 4-10 zhang)Tao lun yi xie jing dian er chang yong de ji qi xue xi fang fa(jue ce shu, Shen jing wang luo, Zhi chi xiang liang ji, Bei ye si fen lei qi, Ji cheng xue xi, Ju lei, Jiang wei yu du liang xue xi);Di 3 bu fen(di 11-16 zhang)Wei jin jie zhi shi, Nei rong she ji te zheng xuan ze yu xi shu xue xi, Ji suan xue xi li lun, Ban jian du xue xi, Gai l\"u tu mo xing, Gui ze xue xi yi ji qiang hua xue xi deng.},
  annotation = {OCLC: 1008931545},
  file = {E\:\\Zotero\\storage\\S8EC824E\\机器学习周志华.pdf},
  isbn = {978-7-302-42328-7},
  language = {Chinese}
}

@article{zhujunBeiYeSiJiQiXueXiQianYanJinZhanZongShu2015,
  title = {{贝叶斯机器学习前沿进展综述}},
  author = {朱军, 胡文波 and Zhu Jun, Hu Wenbo},
  year = {2015},
  month = jan,
  volume = {52},
  pages = {16},
  issn = {1000-1239},
  doi = {10/ghv799},
  file = {E\:\\Zotero\\storage\\5H7G9ME6\\朱军_Zhu Jun_2015_贝叶斯机器学习前沿进展综述.pdf;E\:\\Zotero\\storage\\NQ3SBS7M\\issn1000-1239.2015.html},
  journal = {计算机研究与发展},
  language = {zh},
  number = {1}
}

@inproceedings{zhuUnpairedImagetoimageTranslation2017,
  title = {Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
  booktitle = {Proceedings of the {{IEEE}} International Conference on Computer Vision},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  year = {2017},
  pages = {2223--2232},
  file = {E\:\\Zotero\\storage\\9B667JU6\\Zhu et al_2017_Unpaired image-to-image translation using cycle-consistent adversarial networks.pdf;E\:\\Zotero\\storage\\2ITSFSNC\\Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.html;E\:\\Zotero\\storage\\9V4335KQ\\论文网址.html}
}

@book{zorichMathematicalAnalysis2015,
  title = {Mathematical {{Analysis I}}},
  author = {Zorich, Vladimir A.},
  year = {2015},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-48792-1},
  file = {E\:\\Zotero\\storage\\NXNQHUUF\\Zorich_2015_Mathematical Analysis I.pdf},
  isbn = {978-3-662-48790-7 978-3-662-48792-1},
  language = {en},
  series = {Universitext}
}

@book{zorichMathematicalAnalysisII2016,
  title = {Mathematical {{Analysis II}}},
  author = {Zorich, Vladimir A.},
  year = {2016},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-48993-2},
  file = {E\:\\Zotero\\storage\\9XRZH5P2\\Zorich_2016_Mathematical Analysis II.pdf},
  isbn = {978-3-662-48991-8 978-3-662-48993-2},
  language = {en},
  series = {Universitext}
}


